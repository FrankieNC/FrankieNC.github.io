\documentclass[12pt, a4paper]{article}
\usepackage{francesco}
\usepackage[pdfauthor={Francesco N. Chotuck},
            pdftitle={Complex Analysis Notes},
            ]{hyperref}
\hypersetup{urlcolor=RubineRed,linktoc=all, linkcolor=black, hidelinks}
%\usepackage[none]{hyphenat}

\usepackage{subfig}

\pagestyle{fancy}
\lhead{Francesco Chotuck}
\rhead{5CCM212A Complex Analysis}
\setlength{\headheight}{15pt}
\DeclareMathOperator{\R}{Re}
\DeclareMathOperator{\Arg}{Arg}

\title{Complex Analysis Notes}
\date{}
\author{Francesco Chotuck}

\begin{document}
\maketitle

\begin{abstract}
    This is KCL undergraduate module 5CCM212A, instructed by Professor Simon Scott. The formal name for this class is ``Complex Analysis''.
\end{abstract}

\tableofcontents

\pagebreak

\section{Preliminaries}

\subsection{The complex plane}

The set \(\CC\) can be identified with the vector space \(\RR^2\) with addition and multiplication defined as 
\[\begin{aligned}
    \lambda \begin{pmatrix}
        x \\ y 
    \end{pmatrix} + 
    \begin{pmatrix} 
        a \\b
    \end{pmatrix} &=
    \begin{pmatrix}
        \lambda x+a \\
        \lambda y+b
    \end{pmatrix} \\
    \begin{pmatrix}
        x \\ y 
    \end{pmatrix}
    \cdot
    \begin{pmatrix}
        a \\ b
    \end{pmatrix} &=
    \begin{pmatrix}
        xa-yb \\ xb+ya 
    \end{pmatrix}.
\end{aligned}\]

The set \(\RR^2\) with addition and multiplication rules as defined above is a field, as such it has a \textbf{unit}, which is \(\begin{pmatrix}
    1 \\0
\end{pmatrix}\). This is because
\[
    \begin{pmatrix}
    x \\ y 
    \end{pmatrix} \cdot 
    \begin{pmatrix}
        1 \\0 
    \end{pmatrix} =
    \begin{pmatrix}
        1 \\0 
    \end{pmatrix} \cdot
    \begin{pmatrix}
        x \\ y 
    \end{pmatrix}
    =
    \begin{pmatrix}
        x \\ y 
    \end{pmatrix}.
\]

Notice that we can express the vector 
\[\begin{aligned}
    \begin{pmatrix}
        x \\ y 
    \end{pmatrix} &= 
    \begin{pmatrix}
        x \\ 0
    \end{pmatrix}
    +
    \begin{pmatrix}
        0 \\ y
    \end{pmatrix} \\
    &= 
    \begin{pmatrix}
        x \\ 0 
    \end{pmatrix} +
    \begin{pmatrix}
        0 \\ 1 
    \end{pmatrix}
    \cdot
    \begin{pmatrix}
        0 \\ y 
    \end{pmatrix}.
\end{aligned}\]
On the vector space \(\RR^2\) the vectors \(\begin{pmatrix} x \\ 0 \end{pmatrix}\) and \(\begin{pmatrix} 0 \\ y \end{pmatrix}\) lie on the vector space \(\RR^1\), as such we can create a map from 
\[\begin{aligned}
    \RR^2 &\to \RR^1 \\
    x &\mapsto \begin{pmatrix} x \\ 0 \end{pmatrix} = ``x".
\end{aligned}\]

Note that 
\[\begin{aligned}
    \begin{pmatrix} 0 \\ 1 \end{pmatrix} \cdot \begin{pmatrix} 0 \\ 1 \end{pmatrix} = \begin{pmatrix} -1 \\ 0 \end{pmatrix}.
\end{aligned}\]
Denote \(i = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) then \(i^2 = ``-1"\). Therefore, we can denote the vector 
\[\begin{aligned}
    \begin{pmatrix} x \\ y \end{pmatrix} &= ``x" +i ``y" \\
    &= x+iy \\
    &=z.
\end{aligned}\]

\begin{definition}
    The set \(\CC\) is the set of ordered pairs \(z = (x,y)\) with \(x,y \in \RR\) and the algebraic operations 
    \[\begin{aligned}
        z_1 + z_2 = (x_1,y_1) + (x_2,y_2) &= (x_1+x_2,y_1+y_2) \\
        z_1 \times z_2 = (x_1,y_1) \times (x_2,y_2) &= (x_1x_2 - y_1y_2, x_1y_2+x_2 y_1).
    \end{aligned}\]
\end{definition}

\subsection{Complex numbers}

\begin{definition}
    Suppose \(z \in \CC\) and \(z = x+iy\). The numbers \(x\) and \(y\) are said to be the \textbf{real} and \textbf{imaginary} parts of \(z\) and are denoted by \(\R(z)\) and \(\Img(z)\).
\end{definition}

\begin{definition}
    The \textbf{modulus}, \(\abs{z}\), of \(z=x+iy\) is defined to be distance of \(z\) from the origin so,
    \[\abs{z} = \sqrt{x^2+y^2}.\]
\end{definition}

\begin{mdremark}
    Notice that 
    \[\begin{aligned}
        \abs{x+iy}_{\CC} &= \abs{x+iy} \\
        &= \sqrt{x^2+y^2} \\
        &= \abs{\begin{pmatrix} x \\ y\end{pmatrix}}_{\RR^2}.
    \end{aligned}\]
\end{mdremark}

\begin{definition}
    In the polar coordinates, every non-zero \(z \in \CC\) is defined by a pair \((r,\theta)\) where 
    \[r = \sqrt{x^2+y^2} \quad \text{and} \quad \tan\theta = \frac{y}{x}.\]
    The numbers \(r\) and \(\theta\) are called \textbf{modulus} and the \textbf{argument} of the complex number \(z\) and are denoted by \(\abs{z}\) and \(\arg(z)\), respectively.
\end{definition}

\begin{theorem}
    The argument is not uniquely defined.
\end{theorem}

\begin{proof}
    One can take \(\theta+2 \pi k\) with any \(k \in \ZZ\) instead of \(\theta\).
\end{proof}

\begin{definition}
    The number \(\theta +2 \pi k\) such that \(-\pi < \theta + 2 \pi k \leq \pi\) for \(k \in \ZZ\) is said to be the \textbf{principal value} of the argument and is denoted by \(\Arg(z)\).
\end{definition}

\begin{theorem}[Euler's formula]
    Define \(e^{i\theta} = \cos\theta +i\sin\theta\). Then every non-zero complex number \(z\) can be written in the form \(\abs{z} e^{i \arg(z)}\).
\end{theorem}

\begin{mdthm}[De Moivre's formula]
    For all \(n \in \NN\) we have 
    \[(\cos\theta+i\sin\theta)^n = \cos(n\theta)+i\sin(n\theta).\]
\end{mdthm}

\begin{corollary}
    In particular \(\abs{z_1 z_2} = \abs{z_1} \abs{z_2}\).
\end{corollary}

\begin{definition}
    The expression \(\abs{z_1-z_2}\) is the Euclidean distance between \(z_1\) and \(z_2\). 
\end{definition}

\begin{corollary}
    The value \(\abs{z}\) is the distance from \(z\) to the origin.
\end{corollary}

\begin{mdremark}
    The triangle inequality, \(\abs{z_1+z_2} \leq \abs{z_1} + \abs{z_2}\), holds.
\end{mdremark}

\begin{definition}
    The complex number \(\overline{z} = x-iy\) is called the \textbf{complex conjugate}.
\end{definition}

\begin{theorem}
    Results of the complex conjugate:
    \begin{itemize}
        \item \(\overline{z} = \abs{z} e^{-i \arg(z)}\);
        \item \(z\overline{z}= \abs{z}^2\);
        \item \(\overline{z_1z_2} = \overline{z_1} \cdot \overline{z_2}\);
        \item \(\overline{\left(z\inv \right)} = \left( \overline{z} \right)\inv\);
        \item \(\overline{\left( z_1 \pm z_2 \right)} = \overline{z_1} \pm\overline{z_2}\);
        \item \(\overline{\left( \frac{z}{w} \right)} = \frac{\overline{z}}{\overline{w}}\) if \(w \neq 0\);
        \item \(z+\overline{z} = 2 \R(z)\);
        \item \(z-\overline{z} = 2i \Img(z)\).
    \end{itemize}
\end{theorem}

\subsubsection{The exponential function}

\begin{definition}
    For \(z = x+iy \in \CC\) where \(x,y \in \RR\) we define the \textbf{complex exponential}, denoted by \(e^z\), as follows 
    \[\begin{aligned}
        e^z &= e^{x+iy} \\
        &= e^x e^{iy} \\
        &= e^x (\cos x +i \sin y).
    \end{aligned}\]
\end{definition}

\begin{proposition}
    Some properties of the exponential function:
    \begin{enumerate}
        \item \(e^0 =1\);
        \item \(e^{z+w}=e^z e^w\) for all \(z,w \in \CC\),
        \item \(e^z \neq 0\) for all \(z \in \CC\),
        \item for \(z \in \CC\), \(e^{z+2\pi i}=e^z\),
        \item for \(z \in \CC\), \(\abs{e^z}=e^{\R(z)}\),
        \item \(\overline{\exp(z)}=\exp(\overline{z})\).
    \end{enumerate}
\end{proposition}

\begin{mdremark}
    In general, if \(\varphi\)is a holomorphic function with \(\varphi\) and \(\varphi(\overline{z})\) are defined then 
    \[\varphi(\overline{z}) = \overline{\varphi(z)}.\]
\end{mdremark}

\subsubsection{Trigonometric and hyperbolic functions}

\begin{definition}
    One can define the hyperbolic functions as 
    \[\begin{aligned}
        \sinh(z) &= \half \left( e^z -e^{-z} \right) \\
        \cosh(z) &= \half \left( e^z +e^{-z} \right).
    \end{aligned}\]
\end{definition}

\begin{definition}
    We define the trigonometric functions 
    \[\begin{aligned}
        \sin(z) &= \frac{1}{2i}\left( e^{iz} - e^{-iz} \right) \\
        \cos(z) &= \half \left( e^{iz}+e^{-iz} \right).
    \end{aligned}\]
\end{definition}

\begin{mdthm}[Osborn's rule]
    A key relation between the trigonometric and hyperbolic functions:
    \[\cos(iz) = \cosh(z) \quad \text{and} \quad \sin(iz)=i\sinh(z).\]
\end{mdthm}

\begin{corollary}
    We have 
    \[\cos(z)=\cosh(iz) \quad \text{and} \quad i\sin(z)=\sinh(iz).\]
\end{corollary}

\begin{proof}
    Using Osborn's rule and \(z=iz\) the identities follow.
\end{proof}

\begin{theorem}
    The addition/subtraction rules for both trigonometric and hyperbolic functions hold in \(\CC\)
\end{theorem}

\subsection{Geometry of the complex plane}

We can identify \(\CC\) as a set with the points in the plane \(\RR^2\).

\begin{definition}
    The complex plane is (sometimes) called the \textbf{Argand plane}.
\end{definition}

\begin{figure}[H]
     \begin{center}
         \includegraphics[scale=0.5]{./Resources/Argand diagram.png}
     \end{center}
    \caption{The complex number \(x+iy\) in the complex plane.}
\end{figure}

\subsubsection*{Geometric meaning of complex addition}

With this identification of \(\CC\) it is clear that addition of complex numbers is just addition of vectors in \(\RR^2\). By addition of vectors, we mean completing the parallelogram formed by the line segment joining \((0,0)\) to each of the two complex numbers as sides, and then taking the endpoint of the diagonal from \((0,0)\) as the sum of the two given complex numbers. We illustrate this below.

\begin{figure}[H]
     \begin{center}
         \includegraphics[scale=0.75]{./Resources/Complex addition.png}
     \end{center}
     \caption{Geometric meaning of complex addition.}
\end{figure}

\subsubsection*{Geometric meaning of complex multiplication}

For two complex numbers expressed in polar coordinates as 
\[\begin{aligned}
    z_1 &= r_1 (\cos\theta_1+i\sin\theta_1) \\
    z_2 &= r_2(\cos\theta_2+i\sin\theta_2),
\end{aligned}\]

we have that 
\[\begin{aligned}
    z_1 \cdot z_2 &= r_1 (\cos\theta_1+i\sin\theta_1) \cdot r_2(\cos\theta_2+i\sin\theta_2) \\
    &= r_1 r_2 (\cos(\theta_1+\theta_2) +i\sin(\theta_1+\theta_2)).
\end{aligned}\]

Thus, \(z_1 \cdot z_2\) has polar coordinates \((r_1r_2, \theta_1+\theta_2)\). That is, the angles \(z_1\) and \(z_2\) make with the positive \(\R(z)\) axis are \textit{added} in order to get the angle \(z_1 \cdot z_2\) makes with the positive \(\R(z)\) axis, and the distance to the origin are \textit{multiplied} to get the distance \(z_1 \cdot z_2\) has to the origin.

\begin{figure}[H]
     \begin{center}
         \includegraphics[scale=0.5]{./Resources/Geometry of C-multiplication.png}
     \end{center}
     \caption{Geometric meaning of complex multiplication: angles get added and distances to the origin get multiplied.}
\end{figure}

\begin{mdthm}
    Multiplication of \(z\) by \(i\) results in an anticlockwise rotation of \(\frac{\pi}{2} \text{ rad}\).
\end{mdthm}

\subsection{Topological properties}

\begin{figure}[H]
    \centering
    \subfloat[\centering Open disc]{
        \begin{tikzpicture}

            \draw[fill=lightgray!45,dashed, thick] (0,0) circle (2cm);
            
            \draw[Stealth-Stealth,red] (0,0) -- node[below right]{$r$} (1.4142135623731,1.4142135623731);
            
            \filldraw (0,0) circle (1pt);
            
            \node at (0,-0.3){$z_0$};
            
        \end{tikzpicture}
        }
        \qquad \qquad
    \subfloat[\centering Closed disc]{
        \begin{tikzpicture}

            \draw[fill=lightgray!45,thick] (0,0) circle (2cm);
            
            \draw[Stealth-Stealth,red] (0,0) -- node[below right]{$r$} (1.4142135623731,1.4142135623731);
            
            \filldraw (0,0) circle (1pt);
            
            \node at (0,-0.3){$z_0$};
            
        \end{tikzpicture}
        }
\end{figure}

\begin{definition}
    Let \(z_0\) be a fixed point of \(\CC\) and \(r >0\). The set of points \(z \in \CC\) such that \(\abs{z-z_0} <r\) is said to be the \textbf{open disc} of radius \(r\) centred at \(z_0\). We denote this open disc by \(D(z_0,r)\), that is \(D(z_0,r) = \{z \in \CC : \abs{z-z_0} <r\}.\)
\end{definition}

\begin{definition}
    A closed disc is the set \(\overline{D}(z_0,r) = \{z \in \CC : \abs{z-z_0} \leq r\}\).
\end{definition}

\begin{definition}
    A set \(\Omega \subseteq \CC\) is said to be \textbf{bounded} if it is a subset of disc \(D(z_0,r)\).
\end{definition}

\begin{definition}
    A set \(\Omega \subseteq \CC\) is said to be \textbf{bounded} if it is a subset of a disc \(D(z_0,r)\).
\end{definition}

\begin{definition}
    A set \(\Omega \subseteq \CC\) is said to be \textbf{open} if for each \(z_0 \in A\) there exists \(r>0\) such that \(D(z_0,r) \subseteq \Omega\).
\end{definition}

\begin{mdnote}
    A set \(\Omega \subset \CC\) being open implies that \(\Omega\) is two-dimensional and has no boundary points.
\end{mdnote}

\begin{definition}
    A set \(\Omega \subseteq \CC\) is said to be \textbf{closed} if its complement in \(\CC\) is open.
\end{definition}

\begin{mdremark}
    An open disc is an open set and similarly, a closed disc is a closed set.
\end{mdremark}

\begin{theorem}
    A set \(\Omega \subseteq \CC\) is closed if and only if the limit of every convergent sequence of points \(z_n \in \Omega\) also belongs to \(\Omega\).
\end{theorem}

\begin{definition}
    A set \(A \subseteq \CC\) is said to be \textbf{disconnected} if there exists a pair of disjoint open sets \(\Omega_1,\Omega_2 \subseteq \CC\) such that \(A \subseteq \Omega_1 \cup \Omega_2\) and each of these sets contains at least one element of \(A\).
\end{definition}

\begin{definition}
    A set is \textbf{connected} if it is not disconnected.
\end{definition}

\begin{definition}
    Let \(z_0,z_1\in \CC\). A path from \(z_0\) to \(z_1\) is a continuous map \(\gamma : [0,1] \to \CC\) such that \(\gamma(0)=z_0\) and \(\gamma(1)=z_1\).
\end{definition}

\begin{definition}
    A set \(A \subseteq \CC\) is said to be path-connected if every two points \(z_0,z_1 \in A\) can be joined by a continuous path with values in \(A\).
\end{definition}

\begin{theorem}
    Every path-connected set is connected. An open set is a path connected. A general (not open) connected set need not be path-connected.
\end{theorem}

\subsection{Convergence}

\begin{definition}
    The sequence \(\{z_n\}\) \textbf{converges} to a limit \(L \in \CC\) if 
    \[\forall \eps>0, \, \exists N\in \NN \text{ such that } \forall n \geq N \then \abs{z_n -L}<\eps.\]
\end{definition}

\begin{mdthm}
    Let \(\{z_n\}=\{x_n+iy_n\}\) be a complex sequence. Then \(\{z_n\}\) converges in \(\CC \iff \begin{pmatrix} x_n \\y_n\end{pmatrix} \to \begin{pmatrix} x \\y\end{pmatrix}\) in \(\RR^2 \iff\) the \textit{real} sequences \(\{x_n\}=\{\R(z)\}\) and \(\{y_n\}=\{\Img(z)\}\) both converge in \(\RR^1\).
\end{mdthm}

\begin{proposition}
    If \(z_n \to L\) then \(\abs{z_n} \to \abs{L}\) and \(\overline{z_n} \to \overline{L}\).
\end{proposition}

\begin{example}
    Let \(z_n = \frac{1}{n} e^{i\frac{\pi}{4}n}\). We have that \(z_n \to 0\) as \(n \to \infty\) because 
    \[\begin{aligned}
        \abs{z_n -0}_{\CC} &= \abs{\frac{1}{n} e^{i\frac{\pi}{4}n}} \\
        &= \frac{1}{n} \\
        &\to 0 \quad \text{as } n\to \infty.
    \end{aligned}\]
    In \(\RR^2\), we have that \(z_n = \frac{1}{n} \begin{pmatrix} \cos\left( \frac{n\pi}{4} \right) \\ \sin\left( \frac{n\pi}{4} \right) \end{pmatrix}\). As before \(z_n \to 0\) because 
    \[\begin{aligned}
        \abs{z_n - 0}_{\CC} &= \abs{\frac{1}{n} \begin{pmatrix} \cos\left( \frac{n\pi}{4} \right) \\ \sin\left( \frac{n\pi}{4} \right) \end{pmatrix} - \begin{pmatrix} 0 \\ 0\end{pmatrix}}_{\RR^2} \\
        &= \frac{1}{n} \abs{\begin{pmatrix} \cos\left( \frac{n\pi}{4} \right) \\ \sin\left( \frac{n\pi}{4} \right) \end{pmatrix}} \\
        &= \frac{1}{n} \left( \cos^2\left( \frac{n\pi}{4} \right)+\sin^2\left( \frac{n\pi}{4} \right) \right) \\
        &= \frac{1}{n} \\
        &\to 0 \quad \text{as } n\to \infty.
    \end{aligned}\]
\end{example}

\begin{mdnote}
    Therefore, the concept of convergence in \(\CC\) can be thought as the concept of convergence in \(\RR\).
\end{mdnote}

\subsection{Continuity}

\begin{definition}
    Let \(f:S \to \CC\) be a function. Then \(f\) is \textbf{continuous} at \(\alpha \in S\) if 
    \[\forall \eps>0, \, \exists \delta>0 \text{ such that } z\in S \text{ and } \abs{z-\alpha}<\delta \then \abs{f(z)-f(\alpha)}<\eps.\]
    That is, \(\lim_{z \to \alpha} f(z)\) exists and equals \(f(\alpha)\).
\end{definition}

\begin{mdprop}
    The function \(f: \CC \to \CC\) where \(z \mapsto f(z)=u(x,y)+iv(x,y)\), is continuous at \(z_0 = x_0+iy_0 \in \CC\) if and only if it is continuous at \((x_0,y_0) \in \RR^2\) viewed as a function \(f: \RR^2 \to \RR^2\) where \((x,y) \mapsto (u[x,y],v[x,y])\). Furthermore, this is so if and only if \(u,v: \RR^2 \to \RR^1\) are both continuous at \((x_0,y_0)\).
\end{mdprop}

\begin{proposition}
    The usual rules continuity hold in \(\CC\).
\end{proposition}

\begin{proposition}
    The following two statements are equivalent:
    \begin{enumerate}
        \item \(f:V \to W\) is continuous at \(y \in V\).
        \item For each convergent sequence \(v_n \to y\), one has \(f(v_n) \to f(y)\) in \(W\).
    \end{enumerate}
\end{proposition}

\begin{corollary}
    The function \(f : \CC \to \CC\) is continuous at \(w \in \CC\) if and only if for each \(z_n \to w\) one has \(f(z_n)\to f(w)\) in \(\CC\) \(\iff\) \(u(x_n,y_n) \to u(x,y)\) and \(v(x_n,y_n) \to v(x,y)\), where \(z_n = x_n+iy_n, w=x+iy\) and \(f(z)=u(x,y)+iv(x,y)\).
\end{corollary}

\section{Complex differentiability}
\label{sec:C-diff}

\begin{definition}
    Let \(\Omega \subset \CC\) be an open set and \(f : \Omega \to \CC\) then, \(f\) is said to be differentiable at \(\alpha\) if \(f'(\alpha)\) exists, where it is defined as 
    \[\lim_{z \to \alpha} \frac{f(z)-f(\alpha)}{z-\alpha} := f'(\alpha).\]
\end{definition}

\begin{mdremark}
    Since \(\CC\) can be identified with \(\RR^2\) the limit must exist in all directions thus, we require the function to defined on an open set so that the limit is well-defined. Furthermore, as the limit exists in all directions it must particularly exist for the horizontal and vertical direction.
\end{mdremark}

\begin{theorem}
    The statement of differentiability can be equivalently restated as follows:
    \begin{itemize}
        \item Let \(z = +h\) then
        \[\lim_{h \to 0} \frac{f(\alpha+h)-f(\alpha)}{h} = f'(\alpha).\]
        \item There exists \(f'(\alpha) \in \CC\) such that 
        \[\forall \eps>0, \exists \delta_{\eps}>0 \text{ such that } 0<\abs{z-\alpha}<\delta_{\eps} \then \abs{\frac{f(z)-f(\alpha)}{z-\alpha} - f'(\alpha)} < \eps.\]
        \item There exists \(f'(\alpha) \in \CC\) such that 
        \[\forall \eps>0, \exists \delta_{\eps}>0 \text{ such that } 0<\abs{h}<\delta_{\eps} \then \abs{\frac{f(\alpha+h)-f(\alpha)}{h} - \xi} < \eps,\]
        where \(z = \alpha+h\).
        \item There exists a complex number \(f'(\alpha)\) such that 
        \[f(\alpha +h) = f(\alpha)+ h f'(\alpha)+o(h),\]
        i.e. \(f'(\alpha)\) gives \(1^{\text{st}}\) order Taylor approximation to \(f\) near \(\alpha\).
    \end{itemize}
\end{theorem}

\begin{mdremark}
    The ``function'' \(o(h)\) means ``a function which goes to zero faster than \(h\)''. That is, there exists a function \(g(\alpha,h)\) (which we generically denote by \(o(h)\)) such that 
    \[\lim_{h \to 0} \frac{g(\alpha,h)}{h} = 0,\]
    so the limit exists and is zero. Equivalently, 
    \[\forall \eps>0, \exists \delta_{\eps}>0 \text{ such that } 0<\abs{h}<\delta_{\eps} \then \abs{\frac{g(\alpha,h)}{h}}<\eps.\]
\end{mdremark}

\begin{mdprop}
    If \(f\) is differentiable at \(\alpha\) then, \(f\) is continuous at \(\alpha\).
\end{mdprop}

\begin{example}
    The function \(f(z)=z\) is differentiable.
    \[\begin{aligned}
        \frac{f(z+h)-f(z)}{h} &= \frac{z+h-z}{h} \\
        &= \frac{h}{h} \\
        &=1 \to 1 \quad \text{as } h\to 0.
    \end{aligned}\]
    Therefore, \(f\) is differentiable at all \(z \in \CC\) with \(f'(z)=1\).
\end{example}

\begin{example}
    Let \(f(z) = \R(z) \in \CC\). We show that \(f\) is not differentiable at any point \(z \in \CC\).
    \[\begin{aligned}
        \frac{f(z+h)-f(z)}{h} &= \frac{\R(z+h)-\R(z)}{h} \\
        &= \frac{\R(h)}{h} \to \begin{cases}
            1 &\text{as } h \to 0 \text{ with } h=s \in \RR \\
            0 &\text{as } h \to 0 \text{ with } h=it \in \CC.
        \end{cases}
    \end{aligned}\]
\end{example}

\begin{mdexample}
    The function \(f(z)=\overline{z} = x-iy\) is not differentiable.
    \[\begin{aligned}
        \frac{f(z+h)-f(z)}{h} &= \frac{\overline{z+h}-\overline{z}}{h} \\
        &= \frac{\overline{z}+\overline{h}-\overline{z}}{h} \\
        &= \frac{\overline{h}}{h}.
    \end{aligned}\]
    We note that \(h = s+it\) for \(s,t \in \RR^1\). So, if \(t =0\) then we have \(h=s\neq 0\) thus,
    \[\frac{\overline{h}}{h}=\frac{s}{s} = 1 \to 1 \quad \text{as } h=s \to 0.\]
    However, if \(s = 0\) then, \(h=it\) hence,
    \[\frac{\overline{h}}{h} = \frac{\overline{it}}{it} = \frac{-it}{it} = -1 \to -1 \quad \text{as } h=it \to 0.\]
    Therefore, the limit of \(\frac{\overline{h}}{h}\) does not exist as \(h \to 0\) which means \(f(z)=\overline{z}\) is not complex differentiable for any \(z \in \CC\).
\end{mdexample}

\begin{proposition}
    Let \(f,g : \Omega \to \CC\) be functions defined on an open set \(\Omega \subset \CC\). Then if \(f\) and \(g\) are both differentiable at \(\alpha \in \CC\):
    \begin{enumerate}
        \item The sum \(a f + b g\), for \(a,b \in \CC\), is differentiable at \(\alpha\) with 
        \[(a f +b g)'(\alpha)=a f'(\alpha)+b g'(\alpha).\]
        \item The product function \(fg\) is differentiable at \(\alpha\) with 
        \[(fg)'(\alpha) = f'(\alpha)g(\alpha)+f(\alpha)g'(\alpha).\]
        \item If \(g(\alpha) \neq 0\) then the quotient function \(\frac{f}{g}\) is differentiable at \(\alpha\) with derivative 
        \[\left( \frac{f}{g} \right)'(\alpha) = \frac{f'(\alpha)g(\alpha)-f(\alpha)g'(\alpha)}{g^2(\alpha)}.\]
    \end{enumerate}
\end{proposition}

\begin{proposition}
    Let \(f\) and \(g\) be differentiable functions such that \(f\) is defined on an open set \(\Omega\) and differentiable at \(\alpha \in \Omega\) while \(g\) is defined on an open set containing the image \(f(\Omega)\) and differentiable at \(f(\alpha) \in f(\Omega)\). Then the composition \(g \circ f(z) =g(f(z))\) is also differentiable at \(\alpha\) with derivative
    \[(g \circ f)'(\alpha) = g'(f(\alpha))f'(\alpha).\]
\end{proposition}

\begin{mdnote}
    That is, the usual rules of differentiation hold in \(\CC\).
\end{mdnote}

\subsection{Cauchy-Riemann equations}

\begin{definition}
    Let \(f\) be a complex-valued function on an open set \(\Omega \subseteq \CC\). Writing 
    \[f(z) = u(x,y)+i v(x,y) \qquad \text{for } u,v : \RR^2 \to \RR^1, z= z+iy.\]
    We may define \(f_x\) and \(f_y\) by 
    \[\begin{aligned}
        \diffp{f}{x} &:= \diffp{u}{x}+i \diffp{v}{x} \quad \text{or } f_x :=u_x +iv_x, \\
        \diffp{f}{y} &:= \diffp{u}{y}+i \diffp{v}{y} \quad \text{or } f_y :=u_y +iv_y,
    \end{aligned}\]
    when the partial derivatives \(u_x,u_y,v_x,v_y\) exist.
\end{definition}

\begin{theorem}
    Using the identities \(z =x+iy\) and \(\overline{z}=x-iy\) the chain rule gives us 
    \[\begin{aligned}
        \diffp{f}{z} &:= \half \left( \diffp{f}{x}-i\diffp{f}{y} \right)  \quad \text{or } f_z := \half\left( f_x -if_y \right), \\
        \diffp{f}{{\overline{z}}} &:= \half \left( \diffp{f}{x}+i\diffp{f}{y} \right)  \quad \text{or } f_{\overline{z}} := \half\left( f_x +if_y \right).
    \end{aligned}\]
\end{theorem}

\begin{proof}
    Let \(f(z) = f(x+iy) = f(x,y) =u(x,y)+iv(x,y)\). By the chain rule we have
    \[\diffp{f}{z} = \diffp{f}{x} \diffp{x}{z} + \diffp{f}{y} \diffp{y}{z}.\]
    Note that \(z = x+iy\) and \(\overline{z} = x-iy\) imply 
    \[\begin{aligned}
        x &= \half (z + \overline{z}) \\
        y &= \half (z - \overline{z}),
    \end{aligned}\]
    thus, 
    \[\begin{aligned}
        \diffp{x}{z} &= \half \\
        \diffp{y}{z} &= \frac{1}{2i} = - \frac{i}{2}.
    \end{aligned}\]
    Substituting these into \(f_z\) and we have 
    \[\begin{aligned}
        \diffp{f}{z} &= \half \diffp{f}{x} - \frac{i}{2} \diffp{f}{y} \\
        &= \half \left( \diffp{f}{x} - i \diffp{f}{y} \right). \\
        &= \half \left( f_x -i f_y \right).
    \end{aligned}\]
\end{proof}

\begin{theorem}
    As such we can write
    \[\begin{aligned}
        f_z &= \half [(u_x+v_y)+i(v_x-u_y)] \\
        f_{\overline{z}} &= \half [(u_x-v_y)+i(u_y+v_x)].
    \end{aligned}\]
\end{theorem}

\begin{proof}
    Recall that if \(f(z) = u(x,y)+iv(x,y)\) then 
    \[f_x = u_x +iv_x \quad \text{and} \quad f_y = u_y +iv_y.\]
    We have that 
    \[\begin{aligned}
        f_z &= \half (f_x -i f_y) \\
        &= \half [(u_x +iv_x)  - i (u_y +iv_y)] \\
        &= \half [(u_x + v_y)+i(v_x-v_y)].
    \end{aligned}\]
\end{proof}

\begin{mdthm}[Cauchy-Riemann equations]
    Let \(f : \Omega \to \CC\) with \(\Omega \subset \CC\) being open.
    \begin{enumerate}
        \item[(a).] Write \(f(z) = u(x,y)+i v(x,y)\) if \(f\) is differentiable at \(z = x+iy \in \Omega\) then \(u\) and \(v\) have first-order partial derivatives at \((x,y)\) and these satisfy the \textbf{Cauchy-Riemann equations}
        \[u_x = v_y \quad u_y = -v_x.\]
        \item[(b).] Equivalently, the Cauchy-Riemann equations can be written as any of the following evaluated at \((x,y)\):
        \begin{itemize}
            \item \(f_{\overline{z}}=0\) or,
            \item \(f_z=f_x\) or,
            \item \(f_z=-i f_y\) or,
            \item \(f_y=if_x\).
        \end{itemize}
    \end{enumerate}
\end{mdthm}

\begin{mdnote}
    It turns out that, provided we impose continuity conditions on the partial derivatives, we do obtain a converse to the theorem above.
\end{mdnote}

\begin{mdthm}
    If \(f_x\) and \(f_y\) exists and are continuous at \((x,y) \in \Omega\) (that is, if \(u_x,u_y,v_x,v_y\)) exist and are continuous at \((x,y)\), and if they satisfy the Cauchy-Riemann equations at that point then \(f\) is complex differentiable at \(z = x+iy\) and the equations above hold. 
\end{mdthm}

\begin{mdnote}
    With the continuity condition the Cauchy-Riemann equation theorem becomes an `if and only if' statement. That is, suppose \(f_x\) and \(f_y\) exists and are continuous, \(f\) is differentiable on its domain if and only if the Cauchy-Riemann equation hold.
\end{mdnote}

\begin{example}
    Suppose \(f(z)=\overline{z} = x+i(-y)\). We have that \(u(x,y)=x\) and \(v(x,y)=-y\). So, 
    \[\begin{aligned}
        u_x &=1 \quad \text{and} \quad v_x =0 \\
        u_y &=0 \quad \text{and} \quad v_y = -1.
    \end{aligned}\]
    We have that \(u_x \neq v_y\) for all \(x,y \in \RR\) so, the Cauchy-Riemann equations do not hold hence, \(\overline{z}\) is never complex differentiable (as previously shown). 
\end{example}

\begin{mdexample}
    Suppose \(f(z)= \abs{z}^2\). For \(z=x+iy\) we can write 
    \[\begin{aligned}
        f(z) &= \abs{z}^2 \\
        &= z \overline{z} \\
        &= (x+iy)(x-iy) \\
        &= \underbrace{(x^2+y^2)}_{u(x,y)} +i \underbrace{0}_{v(x,y)}.
    \end{aligned}\]
    We have that 
    \[\begin{aligned}
        u_x &= 2x \quad \text{and} \quad v_x =0 \\
        u_y &= 2y \quad \text{and} \quad v_y =0.
    \end{aligned}\]
    The Cauchy-Riemann equations hold when 
    \[\begin{aligned}
        u_x &= v_y \then x=0 \\
        u_y &= -v_x \then y=0.
    \end{aligned}\]
    The CR equations only hold when \(z = 0\) thus, \(\abs{z}^2\) is complex differentiable \textbf{only} at \(z=0\).
\end{mdexample}

\begin{mdcor}
    If the Cauchy-Riemann equations hold then one has 
    \[\begin{aligned}
        f'(z) &= f_z(x,y) \\
        &= f_x(x,y) \\
        &= -if_y(x,y).
    \end{aligned}\]
    Where 
    \[\begin{aligned}
        f_x(x,y) &= u_x(x,y)+i v_x(x,y) \\
        -if_y(x,y) &= v_y(x,y) -i u_y(x,y).
    \end{aligned}\]
\end{mdcor}

\subsection{Holomorphic functions}

\begin{definition}
    A complex-valued function \(f\) which is differentiable at every point on an open set \(\Omega \subset \CC\) is said to be \textbf{holomorphic} in \(\Omega\). The set of functions holomorphic in \(\Omega\) is denoted by \(H(\Omega)\).
\end{definition}

\begin{definition}
    Functions which are holomorphic everywhere, any \(f \in H(\CC)\), are called \textbf{entire}.
\end{definition}

\begin{proposition}
    The set \(H(\Omega)\) is a vector space. Furthermore, it is an 'algebra' i.e. the product \(f \cdot g \in H(\Omega)\) is defined and if \(g(z) \neq 0\) for all \(z \in \Omega\), then also \(\frac{f}{g} \in H(\Omega)\) is defined.
\end{proposition}

\begin{mdexample}
    Examples of holomorphic functions:
    \begin{itemize}
        \item Any polynomial of the form \(p(z) = \sum_{n=0}^N a_n z^n\), for complex constants \(a_n \in \CC\) is an entire function.
        \item Any polynomial containing non-zero powers of \(\overline{z}\) are \textbf{NOT} holomorphic.
        \item Rational functions \(\frac{p(z)}{q(z)}\) where \(p(z)\) and \(q(z)\) are polynomial are holomorphic on the open set in which \(q(z)\) is never zero.
        \item The exponential function.
        \item The trigonometric and hyperbolic functions since \(e^z \in H(\CC)\).
    \end{itemize}
\end{mdexample}

\begin{theorem}
    The usual rules of differentiation hold (these are illustrated in the \hyperref[sec:C-diff]{Complex differentiability} section)
\end{theorem}

\begin{mdthm}
    The function \(f\) is holomorphic if and only if \(f\) is continuously differentiable (i.e. the derivative is continuous) and it satisfies the Cauchy-Riemann equations at each point in its domain. Mathematically,
    \[f \in H(\Omega) \iff f \in C^1(\Omega)\]
    and the C-R equations are satisfied for each \(z \in \Omega\).
\end{mdthm}

\begin{theorem}
    Holomorphy implies continuity.
\end{theorem}

\begin{mdprop}[Constancy in a region]
    Suppose \(f \in H(\Omega)\). Then any of the following conditions forces \(f\) to be constant in \(\Omega\):
    \begin{enumerate}
        \item \(f'(z)=0\) for all \(z \in \Omega\);
        \item \(f(z)\) is real for all \(z \in \Omega\);
        \item \(\abs{f} = \text{constant}\) in \(\Omega\).
    \end{enumerate}
\end{mdprop}

\begin{proof}
    We split the proof into parts.
    \begin{enumerate}
        \item We have that \(f'(z) = u_x +iv_x\). If \(f'(z)=0\) then
        \[u_x =-iv_x \then u_x=v_x=0.\]
        By the Cauchy-Riemann equations we have, \(u_y=v_y=0\) hence, \(f\) must constant.
        \item If \(f\) is real-valued, then \(v=0\) which implies \(v_x=v_y=0\). By the Cauchy-Riemann equations, \(u_x=u_y =0\) too. Hence, by \((1)\) \(f\) must be constant.
        \item If \(\abs{f}=0\) then, \(f=0\). Suppose \(\abs{f}=a\neq 0\) then, \(\abs{f}^2= f \cdot \overline{f}=a^2\); consequently, the function 
        \[\overline{f} = \frac{a^2}{f} \in H(\Omega).\]
        This implies that the real-valued functions 
        \[\R(f) = \half \left( f+ \overline{f} \right) \quad \text{and} \quad \Img(f) = \frac{1}{2i} \left( f-\overline{f} \right)\]
        are also holomorphic. By property \((2)\), both of these functions are constant.
    \end{enumerate}
\end{proof}

\section{Complex logarithm}

\begin{mdremark}
    When writing \(\log\) in this course we mean \(\ln\).
\end{mdremark}

We define the logarithm on \((0,\infty) \subset \RR\) as the function which is inverse to the exponential function: for each positive real number \(x\), there exists a unique real solution \(t = \log(x) = \ln(x)\) to the equation \(e^t=x\). In the complex case we seek solutions to the equation \(e^w=z\). 

Suppose \(z \in \CC\) and \(z\neq 0\). Let \(z = e^w = e^{u+iv}\) for \(u,v \in \RR\). Then,
\[\abs{z} = \abs{e^u e^{iv}}=e^u \quad \text{and} \quad \arg(z)=\{v+2\pi k : k \in \ZZ\}.\]

We have derived the important relation 
\[e^w =z \iff w = \log\abs{z}+i\arg(z).\]

A problem arises: by this definition the logarithm is not holomorphic! We provide a new definition.

\begin{definition}
    Let \(\Omega \subset \CC\) be an open simply connected set. A \textbf{branch of the logarithm} on \(\Omega\) is the logarithm defined by 
    \[\log_{\theta} = \log_{\RR}\abs{z} + i\arg_{\theta}(z) \quad \text{for } \Omega=\CC \backslash R_{\theta},\]
    where
    \[\theta-\pi < \arg_{\theta}(z) < \theta+\pi.\]
\end{definition}

\begin{mdremark}
    Usually the argument of a complex number, \(\arg(z)\), is defined on \(-\pi < \arg(z) \leq \pi\). Whereas, for the argument in the logarithm is defined with strict inequalities.
\end{mdremark}

\begin{mdremark}
    Simply connected set means it has no holes, since in \(\RR\) the logarithm is not defined for \(0\) we must delete that point along with a line to make the new `complex plane' simply connected. Thus, we delete a half-line and the origin from \(\CC\) to make such a set. This line \(R_{\theta}\) is the line opposite the ray emanating at angle \(\theta\). Below we illustrate the line \(R_{\theta}\).
    \begin{figure}[H]
         \begin{center}
            \resizebox{10cm}{!}{%
            \begin{tikzpicture}
                \draw[-Stealth,ultra thick] (-5,0)--(5,0) node[right]{$\text{Im}(z)$};
                \draw[-Stealth,ultra thick] (0,-5)--(0,5) node[above]{$\text{Re}(z)$};
                \draw[thick,dashed,red] (0,0) -- (5,5);
                \draw[thick, red] (0,0) -- (-5,-5);
                
                \node[red] at (-2.5,-2){$R_{\theta}$};
                
                \draw[->,thick] (1,0) arc (30:45:2.5);
                
                \node at (1,0.5){$\theta$};
                
                \node[above left] at (0,0){$O$};
                
                \end{tikzpicture}}
         \end{center}
    \end{figure}
\end{mdremark}


\begin{definition}
    Taking \(\theta=0\) gives what is known as the \textbf{principal value logarithm}
    \[\text{Log}(z) := \log_0(z) = \log_{\RR}\abs{z}+i\arg_0(z)\]
    with 
    \[-\pi < \arg_0(z)<\pi.\]
\end{definition}

\begin{mdremark}
    Usually the argument of a complex number, \(\arg(z)\), is defined on \(-\pi < \arg(z) \leq \pi\). Whereas, for the argument in the logarithm is defined with strict inequalities.
\end{mdremark}

\begin{proposition}
    For \(z,w \in \CC \backslash R_{\theta}\)
    \begin{enumerate}
        \item \(e^{\log_{\theta}(z)}=z\).
        \item \(\log_{\theta}(e^z)=z+i(2\pi k)\) for some \(k \in \ZZ\).
        \item \(\log_{\theta}(zw)=\log_{\theta}(z)+\log_{\theta}(w)+i(2\pi k)\) for some \(k \in \ZZ\).
        \item \(\log_{\theta} \left( \frac{1}{z} \right) = \log_{\theta}(z\inv) = -\log_{\theta}(z)+i(2\pi k)\) for some \(k \in \ZZ\).
    \end{enumerate}
\end{proposition}

\begin{mdexample}
    Evaluate \((i)\) \(\text{Log}(-1+i\sqrt{3})\), \((ii)\) \(\log_{\frac{\pi}{4}}(-1+i\sqrt{3})\), \((iii)\) \(\log_{\frac{-3\pi}{2}}(-1+i\sqrt{3})\).
    \begin{solution}
        We present the solution to each problem.
        \begin{enumerate}
            \item[\((i)\)] \(\text{Log}(-1+i\sqrt{3}) = \log_0(-1+i\sqrt{3}) = \log_{\RR}(2) + i \arg_0(-1+i\sqrt{3})\). This is the `usual' \(\arg\) but is defined on \(-\pi<\arg(z)<\pi\). By sketching the point on an Argand diagram it follows that \(\arg_0(-1+i\sqrt{3}) = \pi - \arctan\left( \sqrt{3} \right) = \pi - \frac{\pi}{3} = \frac{2\pi}{3}\). We conclude that 
            \[\text{Log}(-1+i\sqrt{3}) = \log(2)+ i\left( \frac{2\pi}{3} \right).\]
            \item[\((ii)\)] \(\log_{\frac{\pi}{4}}(-1+i\sqrt{3}) = \log_{\RR} \left( 2 \right) + i \arg_{\frac{\pi}{4}} (-1+i\sqrt{3})\). The argument is now defined on \(-\frac{3\pi}{4} < \arg_{\frac{\pi}{4}}(z)< \frac{5\pi}{4}\). It follows that the argument is the same as before and so,
            \[\log_{\frac{\pi}{4}}(-1+i\sqrt{3}) = \log \left( 2 \right) + i \left(  \frac{2\pi}{3} \right).\]
            \item[\((iii)\)] \(\log_{\frac{-3\pi}{2}}(-1+i\sqrt{3}) = \log_{\RR}(2)+i\arg_{-\frac{3\pi}{2}}(-1+i\sqrt{3})\). The argument is now defined on \(-\frac{5\pi}{2}<\arg_{\frac{-3\pi}{2}}(z)<-\frac{\pi}{2}\). Therefore, the branch \(\Im(z)\geq 0\) has been cut out from the plane. We conclude,
            \[\log_{\frac{-3\pi}{2}}(-1+i\sqrt{3}) = \log(2)+i\left( -\frac{4\pi}{3} \right).\]
        \end{enumerate}
    \end{solution}
\end{mdexample}

\begin{mdthm}
    The function \(\log_{\theta}\) is holomorphic on \(\CC \backslash R_{\theta}\).
\end{mdthm}

\begin{corollary}
    We have that
    \begin{itemize}
        \item \(\diff{\log(z)}{z} = z\inv\) and,
        \item \(\diff{\log(f(z))}{z} = \frac{f'(z)}{f(z)}\).
    \end{itemize}
\end{corollary}

\begin{proposition}
    Properties of the \(\log\).
    \begin{enumerate}
        \item \(\R[\log f(z)] = \log_{\RR}\abs{f(z)}\), where \(\log_{\RR} : (0,\infty) \to \RR\) is  the classical logarithm on the positive reals.
        \item We have that 
        \[\log_1(f)-\log_2(f) = i(2\pi k) \quad \text{for some } k \in \ZZ,\]
        for \(\log_1,\log_2\) any two branches of the logarithm of \(f\) on \(\Omega\). That is, the difference of any two logarithm functions is a constant function.
        \item We have that 
        \[\log_1(f\cdot g)-\log_2(f)-\log_3(g)=i(2\pi k) \quad \text{for some } k \in \ZZ,\]
        for \(\log_1,\log_2,\log_3\) respectively of the logarithm \(f \cdot g, f\) and \(g\) on \(\Omega\) (where \((f\cdot g)(z)= f(z)g(z)\)).
    \end{enumerate}
\end{proposition}


\section{Complex power series}

\subsection{Complex series}

\begin{definition}
    Let \(\{w_n\}_{n \geq 0}\) be a sequence of complex numbers. We say that the infinite series \(\sum_{n=0}^{\infty} w_n\) \textbf{converges} if the sequence of its partial sums \(S_m = \sum_{n=0}^{m} w_n\) converges to a limit \(w \in \CC\) as \(m \to \infty\).
\end{definition}

\begin{mdremark}
    In this course we will use \(\sum w_k < \infty\) to indicate a convergent series and \(\sum w_k = \infty\) to indicate a divergent series.
\end{mdremark}

\begin{mdprop}
    Properties of convergent series.
    \begin{enumerate}
        \item The complex series \(\sum_{n=0}^{\infty}\) converges if and only if the \textbf{real} series \(\sum_{n=0}^{\infty} \R(w_n)\) and \(\sum_{n=0}^{\infty} \Img(w_n)\) converge.
        \item Let \(\sum_{n=0}^{\infty} w_n\) and \(\sum_{n=0}^{\infty} v_n\) be convergent series. Then, for all \(\alpha,\beta \in \CC\) the series 
        \[\sum_{n=0}^{\infty} (\alpha w_n +\beta b_n) =\alpha\sum_{n=0}^{\infty}w_n +\beta\sum_{n=0}^{\infty} v_n,\]
        is convergent.
        \item The series \(\sum_{n=0}^{\infty}\) is convergent if and only if the partial sum \(S_m\) is a Cauchy sequence.
        \item If there exists \(z_n \in (0,\infty)\) positive real numbers with \(\abs{w_n}<z_n\) for \(k>M\in \NN\), and if \(\sum_{n=0}^{\infty}<\infty\) then \(\sum_{n=0}^{\infty} w_n <\infty\).
    \end{enumerate}
\end{mdprop}

\begin{definition}
    If \(\sum_{n=0}^{\infty} \abs{w_n} < \infty\), the series \(\sum_{n=0}^{\infty} w_n\) is said to be \textbf{absolutely convergent}.
\end{definition}

\begin{corollary}
    Every absolutely convergent series converges.
\end{corollary}

\subsubsection{Testing for convergence}

\begin{proposition}[The \(n^{\text{th}}\) root test]
    Let 
    \[\limsup_{n \to \infty} \abs{w_n}^{\frac{1}{n}} = L.\]
    Then the series \(\sum w_n\) converges absolutely if \(L<1\) and diverges if \(L>1\).
\end{proposition}

\begin{proposition}[Ratio test]
    Assume \(w_n \neq 0\) and that sequence 
    \[\frac{\abs{w_{n+1}}}{\abs{w_n}}\] 
    converges. Let 
    \[\lim_{n\to \infty} \frac{\abs{w_{n+1}}}{\abs{w_n}} = L,\]
    then the series \(\sum w_n\) converges absolutely if \(L<1\) and diverges if \(L>1\).
\end{proposition}

\subsection{Power series}

\begin{definition}
    A \textbf{power series} is defined to be a series of the form 
    \[\sum_{n=0}^{\infty} c_n(z-a)^n,\]
    where \(a \in \CC\) and \(c_n \in \CC\) (and \(n\geq 0\)).
\end{definition}

\begin{mdprop}
    For any complex power series \(\sum c_n (z-a)^n\) there is a value 
    \[0 \leq R \leq \infty\]
    such that if \(0 < R < \infty\) then the series converges 
    \begin{itemize}
        \item absolutely for those \(z\) with \(\abs{z-a}<R\) i.e. \(z \in D(a,R)\),
        \item diverges for those \(z\) with \(\abs{z-a} >R\) i.e. \(z \not\in D(a,R)\).
    \end{itemize}
    However, 
    \begin{itemize}
        \item If \(R = \infty\) then the series converges absolutely for all \(z \in \CC\).
        \item If \(R=0\) then the series is divergent for all \(z \neq a\).
    \end{itemize}
\end{mdprop}

\begin{definition}
    The number \(R\) from above is called the \textbf{radius of convergence} of the power series \(\sum_{n=0}^{\infty} c_n(z-a)^n\).
\end{definition}

\begin{mdprop}
    For a complex series \(\sum_{n=0}^{\infty} c_n (z-a)^n\) the radius of convergence is given by:
    \begin{itemize}
        \item \(R = \left( \limsup_{n \to \infty} \abs{c_n}^{\frac{1}{n}} \right)\inv =\frac{1}{\limsup_{n \to \infty} \abs{c_n}^{\frac{1}{n}}}\);
        \item assuming \(c_n \neq 0\), if the sequence \(\frac{\abs{c_n}}{\abs{c_{n+1}}}\) converges then 
        \[R = \lim_{n \to \infty} \frac{\abs{c_n}}{\abs{c_{n+1}}}.\]
    \end{itemize}
\end{mdprop}

\begin{mdremark}
    We can consider \(\limsup\) the same as \(\lim\).
\end{mdremark}

\begin{mdnote}
    An easy way to determine the radius of convergence is to find the largest open disc for which the function is valid in thus, find the poles (singularities) of the function (only if possible).
\end{mdnote}

\subsection{Properties of power series}

\begin{mdthm}
    Let \(R>0\) be the radius of convergence of the power series 
    \[f(z) = \sum_{n=0}^{\infty} c_n (z-a)^n.\]
    Then, \(f\) is \textbf{uniformly convergent} on the open disc \(D(a,r)\) for any \(r<R\), and one has 
    \[f \in H(D(a,R)).\]
\end{mdthm}

\begin{corollary}
    For a power series 
    \[f(z) = \sum_{n=0}^{\infty} c_n (z-a)^n,\]
    with radius of convergence \(R\) has derivative is 
    \[f'(z) = \sum_{n=0}^{\infty} nc_n (z-a)^{n-1} = \sum_{n=0}^{\infty} (n+1) c_{n+1} (z-a)^n\]
    with the same radius of convergence, \(R\).
\end{corollary}

\begin{mdthm}[Fundamental Theorem of Holomorphic Funcions (Discs)]
    A function, \(f \in H(\Omega)\) if and only if \(f\) is \(\CC\) analytic on \(\Omega\).
\end{mdthm}

\begin{mdremark}
    By analytic, we mean the function can be written as a power series.
\end{mdremark}

\begin{mdnote}
    This is a powerful theorem as it implies that a function which is holomorphic in an open set \(\Omega \subset \CC\) is such that \(f^{(n)}(z)\) exists for \(z \in \Omega\) for all \(n\).
\end{mdnote}

\begin{mdcor}
    The function \(f(z) = \sum_{n=0}^{\infty} c_n (z-a)^n\) is infinitely differentiable (i.e. \(f^{(m)}(z)\) exists and is holomorphic for all \(m \in \NN\)) on \(D(a,R)\) with 
    \[f^{(m)}(z) = \sum_{n=m}^{\infty} n(n-1) \cdots (n-(m-1)) c_n (z-a)^{n-m}.\]
    Thus, Taylor's formula holds in \(\CC\) i.e. 
    \[f(z) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(z-a)^n.\]
\end{mdcor}

\subsubsection{Multiplying power series}

\begin{theorem}
    Suppose that 
    \[f(z)=\sum_{n=0}^{\infty} a_n z^n \quad \text{and} \quad \sum_{n=0}^{\infty} b_n z^n\]
    are complex power series with radii of convergence \(R_1\) and \(R_2\) respectively. Let 
    \[h(z)=\sum_{n=0}^{\infty} c_n z^n,\]
    where 
    \[c_n = \sum_{r=0}^{n} a_r b_{n-r}.\]
    Then \(\sum_{n=0}^{\infty} c_n z^n\) has radius of convergence at least \(R:= \min\{R_1,R_2\}\) and 
    \[h(z)=f(z)g(z)\]
    for \(\abs{z}<R\).
\end{theorem}   

\subsection{Geometric series}

\begin{definition}
    The \textbf{geometric series} is defined to be the sum \(\sum_{n=0}^{\infty} z^n\).
\end{definition}

\begin{mdthm}
    We have that the geometric series 
    \[\begin{aligned}
        \sum_{n=0}^{\infty} z^n \begin{cases}
            \text{converges} &\text{if } \abs{z}<1 \\
            \text{diverges} &\text{if } \abs{z} \geq 1.
        \end{cases}
    \end{aligned}\]
    Furthermore, for \(\abs{z}<1\) we have
    \[\sum_{n=0}^{\infty} z^n = \frac{1}{1-z}.\]
\end{mdthm}

\begin{proof}
    Let the partial sum
    \[\begin{aligned}
        S_k &= \sum_{n=0}^{k} z^n \\
        &= 1+z+z^2+ \cdots + z^n.
    \end{aligned}\]
    Multiplying both sides by \(z\) we have 
    \[zS_k = z+z^2+ \cdots + z^{n+1}.\]
    Subtracting the two equations 
    \[S_k - zS_k = (1+z+z^2+\cdots +z^n) -(z+z^2 \cdots +z^{n+1}),\]
    which becomes 
    \[(1-z)S_k = 1-z^{n+1}.\]
    Therefore, 
    \[S_k = \sum_{n=0}^{k} z^k = \frac{1-z^{n+1}}{1-z}.\]
    For \(\abs{z}<1\) the term \(z^{n+1} \to 0\) as \(n \to \infty\) hence,
    \[\begin{aligned}
        S_\infty &= \sum_{n=0}^{\infty} z^n \\
        &= \frac{1}{1-z}. \\
        &= (1-z)\inv
    \end{aligned}\]
\end{proof}

\begin{definition}
    The \textbf{geometric identity} is given by 
    \[(1-z)(1+z+\cdots +z^n)= 1-z^{n+1}.\]
\end{definition}

\subsubsection{Expansion derived from the geometric series}

The geometric series can be viewed in two ways: either as summing an infinite series or as expanding \((1-z)\inv\) as a series when \(\abs{z}<1\). Taking the second viewpoint we may derive many related expansions.

\begin{example}
    Examples of power series.
    \begin{itemize}
        \item Suppose \(f(z) = \frac{1}{1+z}\). Then we may write 
        \[\begin{aligned}
            \frac{1}{1+z} &= \frac{1}{1-(-z)} \\
            &= (1-(-z))\inv \\
            &= 1 + (-z) +(-z)^2 + \cdots \\
            &= 1 - z +z^2 + \cdots \\
            &= \sum_{n=0}^{\infty} (-1)^n z^n  
        \end{aligned}\]
        for \(\abs{z}<1\).
        \item Suppose \(f(z)= \frac{1}{1-z^2}\). Then we may write 
        \[\begin{aligned}
            \frac{1}{1-z^2} &= (1-(z)^2)\inv \\
            &= 1+z^2+z^4 + \cdots \\
            &= \sum_{n=0}^{\infty} z^{2n}
        \end{aligned}\]
        for \(\abs{z} <1\).
        \item Suppose \(f(z) = \frac{1}{z-4}\). Then we may write
        \[\begin{aligned}
            \frac{1}{z-4} &= -\frac{1}{4} \cdot \frac{1}{\left(1-\frac{z}{4}\right)} \\
            &= -\frac{1}{4} \left( 1- \frac{z}{4} \right)\inv \\
            &= -\frac{1}{4} \left( 1+\frac{z}{4} +\frac{z^2}{16} + \cdots \right)\\
            &= - \frac{1}{4} \sum_{n=0}^{\infty} \left( \frac{z}{4} \right)^n \\
            &= - \sum_{n=0}^{\infty} \frac{z^n}{4^{n+1}} 
        \end{aligned}\]
        for \(\abs{\frac{z}{4}}<1\) i.e. \(\abs{z}<4\).
        \item Suppose \(f(z)= \frac{1}{1+z+z^2}\). Then we may write it as 
        \[\begin{aligned}
            \frac{1}{1+z+z^2} &= \frac{1-z}{1-z} \cdot \frac{1}{1+z+z^2} \\
            &=(1-z)\frac{1}{1-z^3}.
        \end{aligned}\]
        Now we express \(\frac{1}{1-z^3}\) as power series:
        \[\frac{1}{1-z^3} = \sum_{n=0}^{\infty} z^{3n}\]
        for \(\abs{z}<1\). Therefore,
        \[\begin{aligned}
            \frac{1}{1+z+z^2} &= (1-z) \sum_{n=0}^{\infty} z^{3n} \\
            &= \sum_{n=0}^{\infty} (z^{3n}-z^{3n+1})
        \end{aligned}\]
        for \(\abs{z}<1\).
    \end{itemize}
\end{example}

\begin{theorem}
    For \(a,b \neq 0\) we can write 
    \[f(z) = \frac{1}{az+b} = \sum_{n=0}^{\infty} (-1)^n \frac{a^n}{b^{n+1}} z^n,\]
    for \(\abs{z} < \frac{\abs{b}}{\abs{a}}\).
\end{theorem}

\begin{proof}
    Let \(f(z)=\frac{1}{az+b}\) then we can write 
    \[\begin{aligned}
        \frac{1}{b+az} &= \frac{1}{b} \cdot \frac{1}{\left( 1 +\left( \frac{a}{b} \right)z \right)} \\
        &= \frac{1}{b} \left( 1+\left( \frac{a}{b} \right)z \right)\inv \\
        &= \frac{1}{b} \left( 1+ \left( \frac{a}{b} \right)z+ \left( \frac{a^2}{b^2} \right)z^2 + \cdots \right) \\
        &= \frac{1}{b} \sum_{n=0}^{\infty}\left( \frac{a}{b} z \right)^n \\
        &= \sum_{n=0}^{\infty} \left( \frac{a^n}{b^{n+1}} \right) z^n,
    \end{aligned}\]
    for \(\abs{\left( \frac{a}{b} \right)z}<1\) i.e. \(\abs{z}<\frac{\abs{a}}{\abs{b}}\).
\end{proof}

\begin{theorem}
    For \(a \neq b\) we have 
    \[f(z) = \frac{1}{(z-a)(z-b)} = \frac{1}{a-b} \sum_{n=0}^{\infty} \left( \frac{1}{b^{n+1}} - \frac{1}{a^{n+1}}\right) z^n\]
    for \(\abs{z}<\min\{\abs{a},\abs{b}\}\).
\end{theorem}

\begin{proof}
    Suppose \(f(z) =\frac{1}{(z-a)(z-b)}\), then we may write using partial fractions 
    \[\begin{aligned}
        f(z) &= \frac{1}{(z-a)(z-b)} \\
        &= \frac{1}{a-b} \cdot \frac{1}{z-a} + \frac{1}{b-a} \cdot \frac{1}{z-b}.
    \end{aligned}\]
    Firstly, we express \(\frac{1}{z-a}\) as a power series:
    \[\begin{aligned}
        \frac{1}{z-a} &= -\frac{1}{a-z} \\
        &= - \frac{1}{a} \cdot \frac{1}{1-\frac{z}{a}} \\
        &= -\frac{1}{a} \sum_{n=0}^{\infty} \left( \frac{z}{a} \right)^n \\
        &= \sum_{n=0}^{\infty} - \frac{1}{a^{n+1}} z^n,
    \end{aligned}\]
    which is valid for \(\abs{z}<\abs{a}\).
    Similarly, we have 
    \[\frac{1}{z-b} = \sum_{n=0}^{\infty} - \frac{1}{b^{n+1}} z^n,\]
    valid for \(\abs{z}<\abs{b}\).
    Substituting the respective power series into \(f(z)\), and we have 
    \[\begin{aligned}
        f(z) &= \frac{1}{a-b}\sum_{n=0}^{\infty} - \frac{1}{a^{n+1}} z^n - \frac{1}{b-a} \sum_{n=0}^{\infty} \frac{1}{b^{n+1}} z^n \\
        &= \frac{1}{a-b}\sum_{n=0}^{\infty}- \frac{1}{a^{n+1}} z^n+ \frac{1}{a-b} \sum_{n=0}^{\infty} \frac{1}{b^{n+1}} z^n \\
        &= \frac{1}{a-b} \sum_{n=0}^{\infty} \left(\frac{1}{b^{n+1}} -\frac{1}{a^{n+1}} \right) z^n.
    \end{aligned}\]
    Therefore, this power series is valid for \(\abs{z}<\min\{\abs{a},\abs{b}\}\).
\end{proof}

\begin{theorem}
    We have that 
    \[\begin{aligned}
        f(z) =\frac{1}{b-z} &= \frac{1}{(b-a)-(z-a)} \\
        &= \sum_{n=0}^{\infty} \frac{1}{(b-a)^{n+1}}(z-a)^n
    \end{aligned}\]
    for \(\abs{z-a}<\abs{b-a}\).
\end{theorem}

\begin{proof}
    Suppose \(f(z) = \frac{1}{b-z}\), and we want to express \(f(z)\) as a power series centred at \(a \in \CC\). Then we may write 
    \[\begin{aligned}
        \frac{1}{b-z} &= \frac{1}{(b-a)-(z-a)} \\
        &= \frac{1}{b-a} \cdot \frac{1}{1-\frac{z-a}{b-a}} \\
        &= \frac{1}{b-a} \sum_{n=0}^{\infty} \left( \frac{z-a}{b-a} \right)^n \\
        &= \sum_{n=0}^{\infty} \frac{1}{(b-a)^{n+1}} (z-a)^n.
    \end{aligned}\]
    This power series is valid for 
    \[\begin{aligned}
        \abs{\frac{z-a}{b-a}} &< 1 \\
        \then \abs{z-a} &< \abs{b-a}.
    \end{aligned}\]
\end{proof}

\begin{example}
    Suppose \(f(z) = \frac{1}{1-z}\) obtain a power series expansion of \(f(z)\) which is valid in a disc centre \(-3\). We can write 
    \[\begin{aligned}
        \frac{1}{1-z} &= \frac{1}{4-(z+3)} \\
        &= \frac{1}{1- \left( \frac{z+3}{4} \right)} \\
        &= \left( 1- \frac{z+3}{4} \right)\inv \\
        &= \sum_{n=0}^{\infty} \left( \frac{z+3}{4} \right)^n \\
        &= \sum_{n=0}^{\infty} \frac{1}{4^{n+1}} (z+3)^n.
    \end{aligned}\] 
    for 
    \[\begin{aligned}
        \abs{\frac{z+3}{4}}&<1 \\
        \abs{z+3} &<4.
    \end{aligned}\]
\end{example}

\subsubsection{Common power series}

\begin{definition}
    We define for \(z \in \CC\),
    \[\begin{aligned}
        e^z &:= 1+z+\frac{z^2}{2!} + \cdots = \sum_{n=0}^{\infty} \frac{z^n}{n!} \\
        \cos(z) &:= 1 -\frac{z^2}{2!}+\frac{z^4}{4!} - \cdots = \sum_{n=0}^{\infty} (-1)^n \frac{z^{2n}}{(2n)!}, \\
        \sin(z) &:= z-\frac{z^3}{3!}+\frac{z^5}{5!}- \cdots = \sum_{n=0}^{\infty} (-1)^n \frac{z^{2n+1}}{(2n+1)!}, \\
        \cosh(z) &:= 1+\frac{z^2}{2!}+\frac{z^4}{4!}+ \cdots = \sum_{n=0}^{\infty} \frac{z^{2n}}{(2n)!}\\
        \sinh(z) &:= z+\frac{z^3}{3!}+\frac{z^5}{5!} + \cdots = \sum_{n=0}^{\infty} \frac{z^{2n+1}}{(2n+1)!}.
    \end{aligned}\]
    These series are valid for all \(z \in \CC\) i.e. their radius of convergence is infinite.
\end{definition}

\begin{proposition}
    One has 
    \[\log_0(1-z) = z+\frac{z^2}{2}+\frac{z^3}{3}+ \cdots = \sum_{n=1}^{\infty} \frac{z^n}{n}\]
    valid for \(z \in D(0,1)\).
\end{proposition}

\subsection{Laurent series}

\begin{definition}
    A \textbf{Laurent series} is a power series of the form 
    \[f(z) := \sum_{n=-\infty}^{\infty} c_n(z-a)^n.\]
\end{definition}

\begin{theorem}
    A Laurent series means 
    \[\sum_{n=-\infty}^{\infty} w_n = \sum_{n=-\infty}^{-1} w_n +\sum_{n=0}^{\infty} w_n,\]
    or equivalently,
    \[\sum_{n=-\infty}^{\infty} w_n = \sum_{m=1}^{\infty} w_{-m} +\sum_{n=0}^{\infty} w_n,\]
    where \(m=-n\).
    If these two series converge respectively to \(L_-,L_+ \in \CC\) then \(\sum_{n=\infty}^{\infty} w_n\) is said to converge to \(L = L_-+L_+\).
\end{theorem}

\begin{mdthm}
    A Laurent power series, \(f(z) = \sum_{n=-\infty}^{\infty} c_n z^n\) is convergent on an annulus 
    \[A(a,R_1,R_2) = \{z \in \CC : R_1 < \abs{z-a} < R_2\}\]
    for real \(R_1,R_2 \in [0,\infty)\); if \(R_2 \leq R_1\) then this is the empty set. We have that 
    \[\begin{aligned}
        R_1 &= \limsup_{n \to \infty} \abs{c_{-n}}^{\frac{1}{n}} \\
        R_2 &= \frac{1}{\limsup_{n \to \infty} \abs{c_n}^{\frac{1}{n}}} = \left( \limsup_{n \to \infty} \abs{c_n}^{\frac{1}{n}} \right)\inv.
    \end{aligned}\]
\end{mdthm}

\begin{mdremark}
    The punctured disc is a degenerate case of an open annulus \(R_1 < \abs{z-a} < R_2,\) where \(R_1 =0\) i.e. a punctured disc centred at \(a\) is of the form 
    \[0<\abs{z-a}<R.\]
\end{mdremark}

\begin{mdnote}
    We can use Laurent series to find a power series which is valid for \(\abs{z} > \alpha\).
\end{mdnote}

\begin{theorem}
    If \(R_1 \geq R_2\) then the series is not convergent anywhere.
\end{theorem}

\begin{mdthm}
    A Laurent series is holomorphic and absolutely convergent inside the annulus \\ \(A(a,R_1,R_2)\).
\end{mdthm}

\begin{mdnote}
    Suppose that \(f\) is holomorphic in \(D(a, r)\). It has a Taylor expansion there and also has a Laurent expansion in \(D'(a,r)\). The uniqueness of the Laurent coefficients forces these expansions to coincide in \(D'(a,r)\) (with \(a_k =0 \) for all \(n<0\)).
\end{mdnote}

\begin{example}
    Determine the power series expansion about \(0 \in \CC\) of the function
    \[f(z) = \frac{1}{(z-i)(z-2)}\]
    in the annuli 
    \begin{enumerate}
        \item[\((i)\)] \(1<\abs{z}<2\) and 
        \item[\((ii)\)] \(\abs{z}>2\).
    \end{enumerate}
    \begin{solution}
        Notice that \(f(z)\) has singularities at \(i\) and \(2\) thus, for each annuli we need to figure out which type of power series we need. We use the method of partial fractions to write 
        \[\begin{aligned}
            f(z) &= \frac{1}{(z-i)(z-2)} \\
            &= \frac{1}{2-i} \left( \frac{1}{z-2} -\frac{1}{z-i} \right).
        \end{aligned}\]
        \begin{enumerate}
            \item[\((i)\)] We want an expansion which is valid for the blue shaded region illustrated below.
            \begin{figure}[H]
                \begin{center}
                   \resizebox{10cm}{!}{%
                   \begin{tikzpicture}
   
                       \draw [name path=B, thick, draw,fill=blue!20](0,0) circle (2cm);    
                       \draw [name path=A, thick, draw,fill=white](0,0) circle (1cm);   
                       \draw [dashed,red,thick](0,0)-- (0.76,0.64);    
                       \draw [dashed,red,thick](0,0)-- (1.13,1.65);    
                       
                       \draw[-Stealth, thick] (-3.66,0) -- (3.66,0) node[right]{$\text{Re}(z)$};      
                       \draw[-Stealth, thick] (0,-3.66) -- (0,3.66) node[above]{$\text{Im}(z)$}; 
                       
                       \begin{scriptsize}    
                       \draw (-1.54,1.94) node {$A(0,1,2)$};    
                       \draw (1.3,0.73) node {$\abs{z}<1$};    
                       \draw (1.6,1.81) node {$\abs{z}<2$};    
                       \end{scriptsize}    
                       \end{tikzpicture}
                       }
                \end{center}
           \end{figure}
           For the term \(\frac{1}{z-2}\) we have a singularity at \(2\), but we want a power series expansion for \(\abs{z}<2\) thus we carry out a Taylor expansion for that term;
            \[\begin{aligned}
                \frac{1}{z-2} &= -\frac{1}{2} \cdot \frac{1}{1-\frac{z}{2}} \\
                &= -\frac{1}{2} \sum_{n=0}^{\infty} \left( \frac{z}{2} \right)^n 
            \end{aligned}\]
            valid for \(\abs{\frac{z}{2}}<1\) i.e. \(\abs{z}<2\). \\
            For the term \(\frac{1}{z-i}\) there is a singularity at \(z=i\) therefore, there exists a Taylor expansion valid for \(\abs{z}<1\), but we need an expansion for \(\abs{z}>1\) so, we must find a Laurent series. To obtain a Laurent series we note that we can write \(\abs{z}>1\) as 
            \[\begin{aligned}
                \frac{\abs{z}}{\abs{z}}&> \frac{1}{\abs{z}}  \\
                \then 1 &>\abs{\frac{1}{z}}
            \end{aligned}\]
            We have that \(\abs{\frac{1}{z}}<1\). We want to find a power with such property so, we can write 
            \[\begin{aligned}
                \frac{1}{z-i} &= \frac{1}{z} \cdot \frac{1}{1-\frac{i}{z}} \\
                &= \frac{1}{z} \sum_{n=0}^{\infty} \left( \frac{i}{z} \right)^n
            \end{aligned}\]
            which is valid for \(\abs{\frac{i}{z}}<1\) i.e. \(\abs{z}>1\). Note that 
            \[\begin{aligned}
                \frac{1}{z-i} &= \frac{1}{z} \sum_{n=0}^{\infty} \left( \frac{i}{z} \right)^n \\
                &= \sum_{n=0}^{\infty} \frac{i}{z^{n+1}} \\
                &= \sum_{m=1}^{\infty} \frac{i^{m-1}}{z^m} \quad (\text{let } m=n+1) \\
                &= \sum_{m=1}^{\infty} i^{m-1} z^{-m} \\
                &= \sum_{n=-\infty}^{-1} i^{-n-1} z^n \quad (\text{let } m=-n). 
            \end{aligned}\]
            Hence, 
            \[\begin{aligned}
                f(z) &= \frac{1}{2-i}\left( -\frac{1}{2} \sum_{n=0}^{\infty} \left( \frac{z}{2} \right)^n + \frac{1}{z} \sum_{n=0}^{\infty} \left( \frac{i}{z} \right)^n \right) \\
                &= \frac{1}{2-i}\left( \sum_{n = -\infty}^{-1} i^{-n-1} z^n - \sum_{n=0}^{\infty} \frac{1}{2^{n+1}} z^n \right).
            \end{aligned}\]
            \item[\((ii)\)] If \(\abs{z}>2\) then \(\frac{1}{z-2} = \frac{1}{z} \sum_{n=0}^{\infty} \left( \frac{2}{z} \right)^n\) and so since the expansion for \(\frac{1}{z-i}\) is the same as before as it is valid for \(\abs{z}>1\). Therefore,
            \[\begin{aligned}
                f(z) &= \frac{1}{2-i} \left( \sum_{n = -\infty}^{-1} i^{-n-1} z^n - \sum_{n=-\infty}^{-1} \frac{1}{2^{n+1}} z^n \right).
            \end{aligned}\]
        \end{enumerate}
    \end{solution}
\end{example}

\section{Integration}

\subsection{Paths and contours}

\begin{definition}
    A \textbf{path} is a continuous function \(\gamma : [a,b] \to \CC\).
\end{definition}

\begin{mdnote}
    In the lecture note we emphasise \([a,b]\) is a non-degenerate interval which means the interval has more than one point.
\end{mdnote}

\begin{mdremark}
    In some texts a `path' is called a `curve'.
\end{mdremark}

\begin{theorem}
    The convention is to take the anticlockwise direction as positive (because the polar angle is increasing).
\end{theorem}

\begin{mdthm}
    A path \(\gamma :[a,b] \to \CC\) is to give two real functions 
    \[x :[a,b] \to \RR \quad \text{and} \quad y:[a,b] \to \CC,\]
    which determine and are determined by \(\gamma\) via
    \[\gamma(t) = x(t)+iy(t)\]
    for each \(t \in [a,b]\).
\end{mdthm}

\begin{definition}
    The geometric image of the map \(\gamma\) is said to be the \textbf{curve} traced out by \(\gamma\) or, simply the \textbf{trace} of \(\gamma\) and is denoted by \(C_{\gamma}\).
\end{definition}

\begin{mdremark}
    Whilst \(\gamma\) determines \(C_{\gamma}\), the converse does not hold. For example, \(\gamma_1(t) = e^{i2\pi t}\) and \(\gamma_2(t) = e^{-i4\pi t}\) with \(t \in [0,1]\) have the same trace: the unit circle around the origin. However, \(\gamma_1\) runs once anticlockwise around the origin and \(\gamma_2\) goes round twice clockwise.
\end{mdremark}

\begin{definition}
    A path is said to be \textbf{simple} if it does not cross itself i.e. \(\gamma(t_1) \neq \gamma_2(t_2)\) for distinct values \(t_1,t_2 (a,b)\).
\end{definition}

\begin{definition}
    A path is said to be \textbf{closed} if \(\gamma(a)=\gamma(b)\).
\end{definition}

\begin{definition}
    If \(\gamma:[a,b] \to \CC\) is a path, then the map \(\wt{\gamma} : [a,b] \to \CC\) given by \(\wt{\gamma}(t)=\gamma(a+b-t)\) is called the \textbf{reverse path}. 
\end{definition}

\begin{mdnote}
    We can think of \(\wt{\gamma}\) as \(\gamma\) traversed in the opposite direction.
\end{mdnote}

\begin{definition}
    A path is said to be \(\textbf{smooth}\) (or continuously differentiable) if the derivative 
    \[\gamma'(t) := x'(t)+iy'(t)\]
    exists and is continuous. (At the point \(a\) we use the right derivative and the point \(b\) the left derivative).
\end{definition}

\begin{definition}
    A \textbf{contour} is a piecewise smooth path i.e. the join of finitely many smooth paths. 
\end{definition}

\begin{mdprop}
    Key parametrisation:
    \begin{itemize}
        \item A straight line which begins at \(a\in \CC\) and ends at \(b \in \CC\):
        \[\gamma:[0,1] \to \CC, \quad \gamma(t)=a(1-t)+tb = a+t(b-a).\]
        \item A circle, \(C(a,r)\), centred at \(a \in \CC\) and of radius \(r>0\):
        \[\gamma:[0,2\pi] \to \CC \quad \gamma=a+re^{it}.\]
    \end{itemize}
\end{mdprop}

\begin{mdremark}
    Sometimes we can write \(\gamma: [0,1] \to [a,b]\).
\end{mdremark}

\subsection{Integration in the complex plane}

\begin{definition}
    The integral of a path \(\phi :[a,b] \to \CC\) is defined by
    \[\int_{a}^{b} \phi(t) \, dt := \int_{a}^{b} x(t) \, dt + i \int_{a}^{b} y(t) \, dt.\]
\end{definition}

\begin{mdremark}
    The integrals denoted here are the usual \(\RR\) integrals.
\end{mdremark}

\begin{lemma}
    The integral of a path is linear i.e. for paths \(\gamma,\phi\):
    \[\int_{a}^{b} \alpha \gamma(t) +\beta \phi(t) \, dt = \alpha \int_{a}^{b} \gamma(t) \, dt +\beta \int_{a}^{b} \phi(t) \, dt \quad \forall \alpha,\beta \in \CC.\]
\end{lemma}

\begin{lemma}
    If \(\phi\) is a smooth path then the fundamental theorem of calculus holds:
    \[\int_{a}^{b} \phi'(t) \, dt = \phi(b)-\phi(a).\]
\end{lemma}

\begin{definition}
    The \textbf{length} of a contour \(\gamma\) is given by 
    \[\int_{a}^{b} \abs{\gamma'(t)} \,dt\] 
    where \(\gamma'\) is the derivative.
\end{definition}

\begin{definition}
    Let \(\gamma:[a,b] \to \CC\) be a smooth path and \(f\) be a continuous complex-valued function in a neighbourhood of \(C_{\gamma}\). Then,
    \[\int_{\gamma} f(z) \, dz = \int_{a}^{b} f(\gamma(t)) \, \cdot \gamma'(t) \, dt.\]
\end{definition}

\begin{definition}
    Let \(\gamma:[a_k,a_{k+1}] \to \CC\) be a smooth path and \(f\) be a continuous function on a neighbourhood of \(C_{\gamma}\) then 
    \[\int_{\gamma} f(z) \, dz := \sum_k \int_{a_k}^{a_{k+1}} f(\gamma(t)) \cdot \gamma'_k(t) \, dt.\]
\end{definition}

\subsection{Properties of complex integration}

\begin{proposition}
    Properties of contour integration. Suppose that \(\gamma:[a,b] \to \CC\) and that \(f:C_{\gamma} \to \CC\) is continuous.
    \begin{enumerate}
        \item \textbf{Reversal.} If \(\wt{\gamma}\) is the reverse path 
        \[\int_{\wt{\gamma}} f(z) \, dz = -\int_{\gamma} f(z) \, dz.\]
        Equivalently,
        \[\int_{-\gamma} f(z) \, dz = -\int_{\gamma} f(z) \, dz.\]
        \item \textbf{Reparametrisation.} The contour integral does not depend on the choice of parametrisation of the contour. More precisely, if \(\gamma:[a,b] \to \CC\) and \(\phi:[\alpha,\beta] \to [a,b]\) with \(\phi(\alpha)=a\) and \(\phi(\beta)=b\) then 
        \[\int_{\gamma_{\phi}} f(z) \, dz = \int_{\gamma} f(z) \, dz,\]
        where \(\gamma_{\phi}(t) = \gamma(\phi(t))\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    We split the proof into parts.
    \begin{enumerate}
        \item We have 
        \[\begin{aligned}
            \int_{\wt{\gamma}} f(z) \, dz &= \int_a^b f(\wt{\gamma}(t)) \cdot \wt{\gamma}'(t) \, dt \\
            &= \int_a^b f(\gamma(a+b-t)) \cdot \gamma'(a+b-t) \cdot (-1) \, dt \\
            &= - \int_a^b f(\gamma(\tau)) \cdot \gamma'(\tau) \, d\tau \\
            &= - \int_{\gamma} f(z) \, dz.
        \end{aligned}\]
        We used \(\tau=a+b-t\).
        \item We have 
        \[\begin{aligned}
            \int_{\gamma_{\phi}} f(z) \, dz &= \int_a^b f(\gamma_{\phi}(t)) \cdot \gamma'_{\phi}(t) \, dt \\
            &= \int_a^b f(\gamma(\phi(t))) \cdot \gamma'(\phi(t)) \, dt \\
            &= \int_{\alpha}^{\beta} f(\gamma(\tau))\cdot \gamma'(\tau) \, d\tau \\
            &= \int_{\gamma} f(z) \, dz,
        \end{aligned}\]
        where \(\tau = \phi(t)\).
    \end{enumerate}
\end{proof}

\begin{mdthm}[Estimation theorem]
    One has 
    \[\abs{\int_{\gamma} f(z) \, dz } \leq \int_a^b \abs{f(\gamma(t))} \cdot \abs{\gamma'(t)} \, dt.\]
    Hence, 
    \[\abs{\int_{\gamma} f(z) \, dz } \leq \abs{\gamma} \sup_{z \in C_{\gamma}} \abs{f(z)},\]
    where \(\abs{\gamma}\) is the length of the contour \(\gamma\).
\end{mdthm}

\begin{proof}
    We use the following fact. For \(\phi:[a,b] \to \CC\) we have 
    \[\abs{\int_a^b \phi(t) \, dt} \leq \int_a^b \abs{\phi(t)} \, dt.\]
    We prove this. Let \(\int_a^b \phi(t) \, dt = re^{i\theta}\), where \(r\geq 0\) and \(\theta \in (-\pi,\pi]\). Then 
    \[\begin{aligned}
        \abs{\int_a^b \phi(t) \, dt} &= r = r e^{-i\theta}e^{i\theta} \\
        &= e^{-i\theta} \int_a^b \phi(t) \, dt \\
        &= \int_a^b e^{-i\theta} \cdot \phi(t) \, dt \\
        &= \int_{a}^{b} \R(e^{-i\theta} \cdot \phi(t)) \, dt + i \int_a^b \Img(e^{-i\theta} \cdot \phi(t)) \, dt.
    \end{aligned}\]
    The LHS is real so, the integral of the imaginary part on the RHS must be zero. Consequently,
    \[\begin{aligned}
        \abs{\int_a^b \phi(t) \, dt} &= \int_a^b \R(e^{-i\theta} \cdot \phi(t)) \, dt \\
        &\leq \abs{\R(e^{-i\theta} \cdot \phi(t))} \, dt \\
        &\leq \int_a^b \abs{e^{-i\theta} \cdot \phi(t)} \, dt \\
        &= \int_a^b \abs{\phi(t)} \, dt.
    \end{aligned}\]
    Now the proof of the theorem is clear, one has 
    \[\begin{aligned}
        \abs{\int_{\gamma} f(z) \, dz} = \abs{\int_a^b \underbrace{f(\gamma(t)) \cdot \gamma'(t)}_{\phi(t)} \, dt}  &\leq \int_a^b \abs{f(\gamma(t)) \cdot \gamma'(t)} \, dt \\
        &\leq \sup_{z \in C_{\gamma}}\abs{f(z)} \int_a^b \abs{\gamma'(t)}\, dt.
    \end{aligned}\]
\end{proof}

\begin{mdexample}
    Let \(f(z)=(z^4+1)\inv\) and let \(\gamma = Re^{it}\) for \(t \in [0,2\pi]\). Then by definition,
    \[\int_{\gamma} f(z) \, dz = \int_0^{2\pi} \frac{Rie^{it}}{R^4e^{i4t}+1} \, dt,\]
    the value of which is not obvious. However, by the estimation theorem we have
    \[\begin{aligned}
       \abs{\int_{\gamma} f(z) \, dz} &\leq \int_{0}^{2\pi} \abs{\frac{Rie^{it}}{R^4e^{i4t}+1}} \, dt \\
       &\leq \frac{R\pi}{\abs{R^4+1}}.
    \end{aligned}\]
\end{mdexample}

\begin{proposition}
    If \(f_m \to f\) uniformly on \(\Gamma\) and if \(C_{\gamma} \subset \Gamma\) then 
    \[\lim_{m} \int_{\gamma} f_m(z) \, dz = \int_{\gamma} \underbrace{\lim_m f_m(z)}_{=f(z)} \, dz.\]
\end{proposition}

\begin{proof}
    By the estimation theorem we have 
    \[\begin{aligned}
        \abs{\int_{\gamma} f(z) \, dz - \int_{\gamma} f_m (z) \, dz} &= \abs{\int_{\gamma} f(z)-f_m(z) \, dz} \\
        &\leq \abs{\gamma} \sup_{z \in \gamma} \abs{f(z)-f_m(z)} \\
        &\to 0
    \end{aligned}\]
    as \(f_m \to f\) uniformly on \(\Gamma\).
\end{proof}

\begin{corollary}
    If a series \(\sum_{n=0}^{\infty} g_n(z)\) is uniformly convergent on \(\Gamma\) then we integrate the series term by term over any contour \(\gamma \in \Gamma\); that is 
    \[\int_{\gamma} \sum_{n=0}^{\infty} g_n(z) \, dz = \sum_{n=0}^{\infty} \int_{\gamma} g_n(z) \, dz.\]
\end{corollary}

\begin{proof}
    Using the proposition above, take \(f_m = \sum_{n=0}^m g_n(z)\).
\end{proof}

\subsection{The fundamental theorem of calculus}

\begin{definition}
    Let \(f\) be a complex function defined on an open set \(\Omega \subset \CC\). A function \(F\) defined on the same set \(\Omega\) is said to be a \textbf{primitive} of \(f\) if \(F\) is holomorphic in \(\Omega\) and \(F'(z) =f(z)\) for all \(z \in \Omega\).
\end{definition}

\begin{mdthm}[FTC]
    Suppose that \(\gamma : [a,b] \to \CC\) and \(F\) is defined on the open set containing the trace of \(\gamma\), \(C_{\gamma}\), and that \(F'(z)\) exists and is continuous at each point of \(C_{\gamma}\). Then
    \[\begin{aligned}
        \int_{\gamma} F'(z) \, dz = \begin{cases}
            F[\gamma(b)]-F[\gamma(a)]   &\text{in general,} \\
            0   &\text{if \(\gamma\) is closed.}
        \end{cases}
    \end{aligned}\]
\end{mdthm}

\begin{proof}
    First assume \(\gamma\) is smooth. The assumptions on \(F\) imply that \(F \circ \gamma\) is differentiable on \([a,b]\) with \((F \circ \gamma)'(t) =F'[\gamma(t)]\gamma'(t)\). Then 
    \[\begin{aligned}
        \int_{\gamma} F'(z) \, dz &= \int_{a}^{b} F'[\gamma(t)]\cdot \gamma'(t) \, dt\\
        &= \int_{a}^{b} (F \circ \gamma)'(t) \, dt \\
        &= \int_{a}^{b} \R[(F \circ \gamma)'(t)] \, dt + i \int_{a}^{b} \Img[(F \circ \gamma)'(t)] \, dt \\
        &= \left[ \R[(F \circ \gamma)'(t)] \right]_a^b+i\left[ \Img[(F \circ \gamma)'(t)] \right]_a^b \\
        &= F[\gamma(b)]-F[\gamma(a)].
    \end{aligned}\]
    Clearly, if the path is closed i.e. \(\gamma(a)= \gamma(b)\) then \(\int_{\gamma} F'(z) \, dz =0\).
\end{proof}

\begin{mdcor}
    If \(f\) has a primitive, \(F \in H(\Omega)\) i.e. \(F'=f\), then for any contour \(\gamma:[a,b] \to \Omega\) we have
    \[\begin{aligned}
        \int_{\gamma} f(z) \, dz = \begin{cases}
            F[\gamma(b)]-F[\gamma(a)]   &\text{in general,} \\
            0   &\text{if \(\gamma\) is closed.}
        \end{cases}
    \end{aligned}\]
\end{mdcor}

\begin{proof}
    Clearly, if \(F'=f\) then 
    \[\begin{aligned}
        \int_{\gamma} f(z) \, dz &= \int_{\gamma} F'(z) \, dz \\
        &= \int_{a}^{b} F'[\gamma(t)] \cdot \gamma'(t) \, dt \\
        &= F[\gamma(b)]-F[\gamma(a)].
    \end{aligned}\]
    If \(\gamma\) is closed then proof is clear.
\end{proof}

\subsection{A fundamental integral}

\begin{mdthm}[The fundamental integral]
    For \(a \in \CC\) and \(r>0\),
    \[\begin{aligned}
        \int_{\gamma(a,r)} (z-a)^n \, dz =\begin{cases}
            0 &\text{if } n \neq -1 \\
            2\pi i &\text{if } n=-1,
        \end{cases}
    \end{aligned}\]
    where \(\gamma(a,r)\) denoted the circular contour having centre \(a\) and radius \(r\).
\end{mdthm}

\begin{proof}
    Let \(f(z) = (z-a)^n\), since \(\gamma(a,r) = a+re^{it}\) for \(t \in [0,2\pi]\) then \(\gamma' = rie^{it}\) thus, we can write 
    \[\begin{aligned}
        \int_{\gamma(a,r)} f(z) \, dz &= \int_{0}^{2\pi} f(a+re^{it}) (a+re^{it})' \, dt \\
        &= \int_{0}^{2\pi} (re^{it})^n rie^{it} \, dt \\
        &= ir^{n+1} \int_{0}^{2\pi} e^{i(n+1)t} \, dt \\
        &= ir^{n+1} \int_{0}^{2\pi} \left( t\cos(n+1) +it \sin (n+1) \right) \, dt \\
        &= \begin{cases}
            ir^{n+1} \left( \left[ \frac{t\sin(n+1)}{n+1} \right]_0^{2\pi} - i \left[ \frac{t\cos(n+1)}{n+1} \right]_0^{2\pi} \right) &\text{if } n\neq -1 \\
            i[1]_0^{2\pi} &\text{if } n=-1.
        \end{cases}
    \end{aligned}\]
\end{proof}

\subsection{Logarithms}

The existence of a primitive depends not only on \(f\) but also on the set \(\Omega\). For instance, if \(\Omega\) is an open disc which does not contain the origin then a continuous branch of the logarithm \(\Omega\), \(\log(z)\) is a primitive for \(f(z)=\frac{1}{z}\). However, the function \(\frac{1}{z}\) does not have a primitive on any open set containing the unit circle, \(S^1\) about the origin because \(\int_{S^1} \frac{1}{z} \, dz \neq 0\) which by the corollary above acts an obstruction to the existence of a primitive.

\begin{mdthm}
    Suppose \(\gamma(0,1)\) is the path of positively oriented unit circle in the plane \(\CC \backslash \{0\}\) then 
    \[\begin{aligned}
        \int_{\gamma(0,1)} \frac{1}{z} \, dz = \begin{cases}
        0 &\text{if \(z\) is outside \(\gamma(0,1)\)} \\
        2\pi i &\text{if \(z\) is inside \(\gamma(0,1)\)}.
        \end{cases}
    \end{aligned}\]
\end{mdthm}

\begin{proof}
    The proof follows from the `fundamental integral proof'.
\end{proof}

\begin{corollary}
    Suppose that \(\Omega\) is a region not containing \(0\). Then there exists a function \(f = \log \in H(\Omega)\) such that \(e^{f(z)}=z\) for all \(z \in \Omega\) and 
    \[f(z)- f(a) =\int_{\gamma} \frac{1}{w} \, dw\]
    for all \(a,z \in \Omega\) where \(\gamma\) is any path in \(\Omega\) with endpoints \(a\) and \(z\).
\end{corollary}

\section{Cauchy integral formula for a disc}

\begin{mdthm}[CIF for a disc]
    Let \(f \in H(D(a,R))\) and let \(\gamma(a,r)\) be a simple positively oriented circle (i.e. it is oriented anticlockwise) about \(a\) with radius \(r <R\). Then if \(z\) is inside \(\gamma\)
    \[\begin{aligned}
        f(z) = \begin{cases}
            \frac{1}{2\pi i} \int_{\gamma(a,r)} \frac{f(w)}{w-z} \, dw &\forall z \in D(a,r) \\
            0 &\forall z \not\in D(a,r).
        \end{cases}
    \end{aligned}\]
\end{mdthm}

\begin{mdnote}
    That is, if the singularity is inside the disc the integral is as given above otherwise, if the singularity is outside the disc the function is \(0\).
\end{mdnote}

\begin{lemma}
    Let \(\Omega \subset \CC\) be open and let \(h : \Omega \times [\alpha,\beta] \to \CC\) with \((w,s) \mapsto h(w,s)\) be a continuous function (in both \(w\) and \(s\)). If the derivative \(\diffp{h}{s}\) exists and is continuous and if \(\gamma :[a,b] \to \Omega\) is a contour, then 
    \[\int_{\gamma} h(w,s) \, dw : \int_{a}^b h(\gamma(t),s) \cdot \gamma'(t) \, dt\]
    is a differentiable function of the variable \(s\) with continuous derivative given by 
    \[\diff{}{s} \int_{\gamma} h(w,s) \, dw = \int_{\gamma} \diffp{}{s}h(w,s) \, dw.\]
\end{lemma}

\begin{mdexample}
    The CIF is useful for \(\RR\) integration. Suppose \(\gamma(t) = e^{it}\) for \(t \in [0,2\pi]\) i.e. a circle centred at the origin of radius \(1\). By the CIF we have
    \[\int_{\gamma} \frac{e^z}{z} \, dz = 2\pi i e^0 =2\pi i.\]
    By direct evaluation we have
    \[\int_{\gamma} \frac{e^z}{z} \, dz = -\int_{0}^{2\pi} e^{\cos t}\sin(\sin t) \, dt + i \int_{0}^{2\pi} e^{\cos t}\cos(\sin t) \, dt.\]
    Since we know the result is \(0+i(2\pi)\) we can compare the real and imaginary parts of the integral, and we conclude that 
    \[\begin{aligned}
        \int_{0}^{2\pi} e^{\cos t}\sin(\sin t) \, dt &= 0 \\
        \int_{0}^{2\pi} e^{\cos t}\cos(\sin t) \, dt &= 2\pi.
    \end{aligned}\]
\end{mdexample}

\subsection{Taylor series coefficients}

\begin{mdremark}
    Emphasis that the centre of the discs described in this section coincide with the singularity of the integral.
\end{mdremark}

\begin{theorem}
    Let \(f \in H(D(a,R))\). Furthermore, let \(r<R\) and \(\gamma(a,r)\) be the positively oriented circle centred at \(a\) of radius \(r\). Then 
    \[f(z) = \sum_{n=0}^{\infty} c_n(a) (z-a)^n \quad \forall z \in D(a,r)\]
    where
    \[c_n(a) = \frac{1}{2\pi i} \int_{\gamma(a,r)} \frac{f(w)}{(w-a)^{n+1}} \, dw\]
    and the series is absolutely and uniformly convergent in the disc \(D(a,r)\).
\end{theorem}

\begin{mdcor}
    Let \(f \in H(D(a,R))\). Furthermore, let \(r<R\) and \(\gamma(a,r)\) be the positively oriented circle centred at \(a\) of radius \(r\). The \(n^{\text{th}}\) derivative, \(f^{(n)}\), satisfies 
    \[\begin{aligned}
        f^{(n)}(a) &= n! c_n(a) \\
        &= \frac{n!}{2\pi i} \int_{\gamma(a,r)} \frac{f(w)}{(w-a)^{n+1}} \, dw \quad \forall r<R
    \end{aligned}\]
\end{mdcor}

\begin{proof}
    By induction.
\end{proof}

\begin{mdcor}[Cauchy's estimate]
    Let \(f \in H(D(a,R))\). Furthermore, let \(r<R\) and \(\gamma(a,r)\) be the positively oriented circle centred at \(a\) of radius \(r\). We have 
    \[\abs{f^{(n)}(a)} \leq \frac{n!}{r^n} \sup_{w \in C_{\gamma(a,r)}}\abs{f(w)} \quad \forall r <R.\]
\end{mdcor}

\begin{proof}
    By above 
    \[f^{(n)}(a) =\frac{n!}{2\pi i} \int_{\gamma(a,r)} \frac{f(w)}{(w-a)^{n+1}} \, dw,\]
    by the estimation theorem we have 
    \[\begin{aligned}
        \abs{f^{(n)}(a)} &= \abs{\frac{n!}{2\pi i} \int_{\gamma(a,r)} \frac{f(w)}{(w-a)^{n+1}} \, dw} \\
        &= \abs{\frac{n!}{2\pi i}} \abs{\int_{\gamma(a,r)} \frac{f(w)}{(w-a)^{n+1}} \, dw} \\
        &\leq \frac{n!}{2\pi} \int_{\gamma(a,r)} \abs{\frac{f(w)}{(w-a)^{n+1}}} \, dw.
    \end{aligned}\]
    Notice the contour \(\gamma(a,r)\) is a circle so, it can be expressed as \(\abs{w-a}<r\), and the length of the contour is \(2\pi r\); as such by applying the estimation theorem again we have 
    \[\begin{aligned}
        \frac{n!}{2\pi} \int_{\gamma(a,r)} \abs{\frac{f(w)}{(w-a)^{n+1}}} \, dw &\leq \frac{n!}{2\pi} \frac{2\pi r}{r^{n+1}}\sup_{z \in C_{\gamma(a,r)}} \abs{f(w)} \\
        &= \frac{n!}{r^n} \sup_{w \in C_{\gamma(a,r)}}\abs{f(w)}.
    \end{aligned}\]
\end{proof}

\subsection{Stocktaking}

\begin{mdthm}
    Let \(f \in H(D(z_0,R))\) and let \(\gamma(z_0,r)\) be a simple positively oriented circle (i.e. it is oriented anticlockwise) about \(a\) with radius \(r <R\). Then \(f^{(n)}(a)\) exists for \(n \in \NN\) and \(n=0\), and we have that 
    \[\begin{aligned}
        \int_{\gamma(z_0,r)} \frac{f(z)}{(z-a)^{n+1}} \, dz =\begin{cases}
            2\pi i f(a) &\text{if \(n=0\) and \(a \in \gamma(z_0,r)\)}, \\
            \frac{2\pi i}{n!} f^{(n)}(a) &\text{if \(n\geq 1\) and \(a \in \gamma(z_0,r)\)}, \\
            0 &\text{if \(a \not\in \gamma(z_0,r)\)}.
        \end{cases}
    \end{aligned}\]
\end{mdthm}

\section{Homotopy of paths}

In this section we define the notion of homotopy. Suppose we have two closed paths in \(\Omega\). Imagine, we have placed a rubber band along \(\gamma_0\). For \(\gamma_0\) to be homotopic to \(\gamma_1\) we should be able to transform the rubber band to get to \(\gamma_1\), with the condition that each intermediate position of the rubber band lies in \(\Omega\).

\begin{mdremark}
    Clearly this is not always possible: consider \(\Omega = \CC \backslash \{0\}\) with \(\gamma_0\) a contour which does not contain the puncture and \(\gamma_1\) a bigger contour containing both \(\gamma_0\) and the puncture. There is no way for the rubber band to transform smoothly due to the obstruction of the puncture at \(\{0\}\).
\end{mdremark}

\begin{definition}
    Let \(\gamma_0,\gamma_1 : [0,1] \to \Omega\) be two \textbf{closed} paths in an open set \(\Omega \subset \CC\). We say that the paths are \textbf{homotopic} in \(\Omega\) if there exists a continuous function 
    \[H: [0,1] \times [0,1] \to \Omega\] 
    such that the following hold:
    \begin{itemize}
        \item[(H1)] For all \(t \in [0,1]\), \(H(t,0)= \gamma_0(t)\).
        \item[(H2)] For all \(t \in [0,1]\), \(H(t,1) = \gamma_1(t)\).
        \item[(H3)] For all \(s \in [0,1]\), \(H(0,s)=H(1,s)\).
    \end{itemize}
    If two paths, \(\gamma_0\) and \(\gamma_1\) are homotopic in \(\Omega\) we write 
    \[\gamma_0 \sim \gamma_1\]
    or possibly 
    \[\gamma_0 \sim_{\Omega} \gamma_1.\]
\end{definition}

\begin{mdnote}
    We can think of \(H\) as a family of closed paths from \([0,1] \to \Omega\) parametrised by ``time'', the \(s\)-variable. We can think of the closed path at time \(s\) as the position of the rubber band at time \(s\): initially, when \(s=0\), \(H(\cdot,0)\) is the path \(\gamma_0\), while finally, when the time \(s=1\), we end up with \(H(\cdot,1)\) which is the path \(\gamma_1\). This is what (H1) and (H2) say. The requirement (H3) says that at each point of time \(s\), the intermediate path \(\gamma_s := H(\cdot,s)\) is closed too. Furthermore, the continuity of \(H\) means that the rubber band never break, and the transformation takes place smoothly.
\end{mdnote}

\begin{example}
    The paths illustrated below are homotopic because they have the same orientation and \(\gamma_1\) can `move' through the plane to deform into \(\gamma_2\).
    \begin{figure}[H]
         \begin{center}
             \includegraphics[scale=0.24]{./Resources/Homotopic paths.png}
         \end{center}
    \end{figure}
\end{example}

\begin{example}
    These paths are NOT homotopic as they have different orientation.
    \begin{figure}[H]
         \begin{center}
             \includegraphics[scale=0.24]{./Resources/Non-Homotopic paths.png}
         \end{center}
    \end{figure}
\end{example}

\begin{example}
   Suppose we have two contours, \(\gamma_1\) and \(\gamma_2\), with a fixed point inside both contours, \(z=a\). If the winding number \(n(\gamma_1,a)\neq n(\gamma_2,a)\) then \(\gamma_1 \not\sim \gamma_2\).
\end{example}

\begin{definition}
    In case a path \(\gamma\) is homotopic to a \textit{point path} (i.e. \(\gamma_p(t)\) is constant for all \(t\)) we write 
    \[\gamma \sim 0.\]
\end{definition}

\begin{mdnote}
    Imagine placing a rubber band along \(\gamma\) and then shrinking it to a point such that each intermediate position of the rubber band is in \(\Omega\) and is closed. If this is possible we say \(\gamma\) is \textbf{contractible}. Indeed, a domain in which \textit{every} closed path is contractible is called \textit{simply connected} i.e. the domain has no holes.
\end{mdnote}

\begin{example}
    \hphantom{yes}
    \begin{figure}[H]
         \begin{center}
             \includegraphics[scale=0.15]{./Resources/Homotopic to a point.png}
         \end{center}
    \end{figure}
\end{example}

\begin{mdthm}
    In \(\CC\) all loops are homotopic to a point i.e. in \(\CC\) we have that \(\gamma_k \sim 0\) for all \(k\).
\end{mdthm}

\begin{proof}
    \(\CC\) has no holes so, any loop can be shrunk into a point.
\end{proof}

\begin{mdexample}
    A loop defined on an annulus cannot be shrunk to a point thus, any loop in an annulus is not homotopic to a point.
\end{mdexample}

\begin{mdthm}[Deformation theorem]
    Suppose \(f \in H(\Omega)\) and that \(\gamma_0 \sim \gamma_1\) in \(\Omega\). Then 
    \[\int_{\gamma_0} f(z) \, dz = \int_{\gamma_1} f(z) \, dz.\]
\end{mdthm}

\begin{proof}
    To simplify the proof we assume the homotopy \(H\) is twice continuously differentiable which allows us to invoke the property to switch the order of partial differentiation:
    \[\diffp{H}{{s}{t}}(t,s) =\diffp{H}{{t}{s}}(t,s).\]
    Let \(\gamma_s :=H(\cdot,s)\) be the intermediate curve at time \(s\). Define 
    \[I(s) := \int_{\gamma_s} f(z) \, dz \quad \text{for }s \in [0,1].\]
    We show that \(\diff{}{s}I(s) =0\) and in particular \(I(0)=I(1)\). We have
    \[\begin{aligned}
        \diff{}{s}I(s) &= \diff{}{s} \int_{\gamma_s} f(z) \, dz = \diff{}{s} \int_{0}^1 f(H(t,s)) \diffp{H}{t}(t,s) \, dt \\
        &= \int_{0}^1 \diffp{}{s} \left( f(H(t,s)) \diffp{H}{t}(t,s) \right) \, dt \\
        &= \int_{0}^{1} \left( f'(H(t,s))\diffp{H}{s}(t,s)\diffp{H}{t}(t,s)+f(H(t,s)) {\color{red}\diffp{H}{{s}{t}}(t,s)}  \right) \\
        &= \int_{0}^{1} \left( f'(H(t,s))\diffp{H}{s}(t,s)\diffp{H}{t}(t,s)+f(H(t,s)) {\color{red}\diffp{H}{{t}{s}}(t,s)}  \right) \\
        &= \int_0^1 \diff{}{t} \left( f(H(t,s)) \diffp{H}{s}(t,s) \right),
    \end{aligned}\]
    and so by FTC,
    \[\begin{aligned}
        \diff{}{s}I(s) &= \int_0^1 \diff{}{t} \left( f(H(t,s)) \diffp{H}{s}(t,s) \right) \\
        &= 0,
    \end{aligned}\]
    since the paths are closed. Clearly, \(I(0)=I(1)\).
\end{proof}

\subsection{Winding numbers}

\begin{mdremark}
    In the following it is, in general, more convenient to parametrise loops using the unit interval \([0,1]\), but any non-degenerate interval \([a,b]\) is also fine.
\end{mdremark}

\begin{definition}
    Let \(\gamma:[0,1] \to \CC \backslash \{0\}\) be a piecewise smooth closed curve in \(\CC\) which does not pass through the origin. Then the \textbf{winding number} of \(\gamma\) about \(0\) is given by 
    \[w_{\gamma} = \frac{1}{2\pi i} \int_{\gamma} \frac{1}{z} \, dz\]
\end{definition}

% \begin{mdnote}
%     The winding number of \(\gamma\) about \(0\), represent how many times the loop goes around \(0\). Since, the path is oriented the winding number can be negative: if the path loops around \(0\) in the anticlockwise direction then it is \(+1\) whereas, if it loops in the clockwise direction it is \(-1\). 
%     (By Jerry i.e. Jiatong He) the winding number can be calculated by drawing a straight line through \(0\) and the path and counting how many times the straight line intersect the path (accounting for orientation).
% \end{mdnote}

\begin{corollary}
    The winding number is given by 
    \[w_{\gamma} =\frac{1}{2\pi i} \int_0^1 \frac{\gamma'(t)}{\gamma(t)} \, dt.\]
\end{corollary}

\begin{proof}
    Clear.
\end{proof}

\begin{mdprop}
    The winding number is an integer i.e. \(w_{\gamma} \in \ZZ\).
\end{mdprop}

\begin{proof}
    This follows from direct evaluation. Let \(\gamma(t) = \rho(t) e^{i\phi(t)}\), where both \(\rho\) and \(\phi\) closed paths and are piecewise differentiable. Then 
    \[\begin{aligned}
        w_{\gamma} &= \frac{1}{2\pi i} \int_{\gamma} \frac{1}{z} \, dz\\
        &= \frac{1}{2\pi i} \left( \int_0^1 \frac{1}{\rho(t) e^{i\phi(t)}} \left( \rho'(t)e^{i\phi(t)}+i\rho(t)\phi'(t)e^{i\phi(t)} \right) \, dt \right) \\
        &= \frac{1}{2\pi i} \left( \int_{0}^{1} \frac{\rho'(t)}{\rho(t)} \, dt + i \int_{0}^{1} \phi'(t) \, dt \right) \\
        &= \frac{1}{2\pi i}\left( \left[ \log\rho(t) \right]_0^1+ i \left[ \phi(t) \right]_0^1 \right) \\
        &= \frac{1}{2\pi i} \cdot 2\pi i k \quad \text{for } k \in \ZZ \\
        &= k \in \ZZ.
    \end{aligned}\]
\end{proof}

\begin{definition}
    Let \(\Omega \subset \CC\) be an open set. To each holomorphic function \(f: \Omega \to \CC \backslash \{0\}\) and each closed contour \(\gamma:[0,1] \to \Omega\) consider the contour 
    \[f \circ \gamma: [0,1] \to \CC \backslash \{0\}, \quad \text{where } t \mapsto f(\gamma(t)).\]
    Define 
    \[w_{\gamma}(f) := w_{f \circ \gamma} \in \ZZ.\]
\end{definition}

\begin{mdcor}
    Assuming that \(f' \in C(\Omega)\) we have 
    \[w_{\gamma}(f) = \frac{1}{2\pi i} \int_{\gamma} \frac{f'(z)}{f(z)} \, dz.\]
\end{mdcor}

\begin{proof}
    By the chain rule \(f(\gamma(t))\) has derivative \(f'(\gamma(t)) \cdot \gamma'(t)\) hence,
    \[\begin{aligned}
        w_{\gamma}(f) &= \frac{1}{2\pi i} \int_{f \circ \gamma} \frac{1}{z} \, dz \\
        &= \frac{1}{2\pi i} \int_{0}^{1} \frac{f'(\gamma(t)) \cdot \gamma'(t)}{f(\gamma(t))} \, dt \\
        &= \frac{1}{2\pi i} \int_{\gamma} \frac{f'(z)}{f(z)} \, dz.
    \end{aligned}\]
\end{proof}

\begin{mdprop}
    Let \(\gamma:[0,1] \to \Omega\) be a closed contour and let \(f,g : \Omega \to \CC \backslash \{0\}\) with \(f,g \in H(\Omega)\) (with continuous derivatives). Then
    \[w_{\gamma}(f \cdot g) = w_{\gamma}(f) + w_{\gamma}(g).\]
\end{mdprop}

\begin{proof}
    Clear with use of this identity:
    \[\frac{(f\cdot g)'(z)}{f(z)g(z)} = \frac{f'(z)}{f(z)}+\frac{g'(z)}{g(z)}.\]
\end{proof}

\begin{definition}
    The \textbf{index} of \(\gamma\) around \(a \in \CC\) (or the \textbf{winding number} of \(\gamma\) around \(a \in \CC\)) is defined to be the integer 
    \[n(\gamma;a):= w_{\gamma}(z-a).\]
\end{definition}

\begin{mdnote}
    This allows us to define the winding number for any point \(a \in \CC\) by a translation of \(a\) from \(0\).
\end{mdnote}

\begin{mdcor}
    We have that
    \[n(\gamma;a) = \frac{1}{2\pi i} \int_{\gamma} \frac{1}{z-a}.\]
\end{mdcor}

\subsubsection{Intuitive meaning of the winding number}

The \textbf{winding number}, \(w_{\gamma}\) of a closed loop \(\gamma\) about the origin is the \textit{net} number of revolutions of the direction of \(z\) as it traces out \(\gamma\) once in its given orientation. The notion of a winding number can be extended to any a point in the plane. We add \(+1\) to \(w_{\gamma}\) after each positive (anticlockwise) revolution of the loop around the point and \((-1)\) for each negative (clockwise) revolution.

\subsubsection{Finding winding numbers quickly}

\begin{mdremark}
    Refer to Visual Complex Analysis book for more explanation \\ (NeedhamVCA.pdf).
\end{mdremark}

\begin{mdthm}
    If a contour \(\gamma\) is moving from our left to our right [our right to our left] as a particle (a moving point) crosses it, its winding number around that point increases [decreases] by one.
\end{mdthm}

An immediate consequence of this result is a connection between, \(w_{\gamma}\) and the number of intersection points of \(\gamma\) with a ray emanating from a point \(p\). We illustrate this property with the figure below, where the \(w_{\gamma}=2\) for \(p\) where each intersection point being marked with \(\bigoplus\) or \(\circleddash\) according as the winding number increases or decreases as it is crossed.

\begin{figure}[H]
     \begin{center}
         \includegraphics[width=\textwidth]{./Resources/Winding number rays.png}
     \end{center}
\end{figure}

\subsubsection{``Inside'' a loop}

\begin{figure}[H]
     \begin{center}
         \includegraphics[width=\textwidth]{./Resources/Inside a loop.png}
     \end{center}
\end{figure}

A typical loop such as \(L\) (as shown above) will partition the plane into a number of sets \(D_j\).

\begin{definition}
    The \textbf{``inside''} of a loop can be defined to be those \(D_j\) for which the winding number is not \(0\) i.e. \(w \neq 0\).
\end{definition}


\begin{definition}
    The \textbf{``outside''} of a loop can be defined to be those \(D_j\) for which the winding number is \(0\) i.e. \(w =0\).
\end{definition}

\subsubsection{Homotopic to a point(extra)}

\begin{mdthm}
    If there exists a singularity ``outside'' the loop then the contour can be deformed into a point. That is, if a loop has a singularity which is ``outside'' then the loop is homotopic to a point.
\end{mdthm}

\subsection{Generalised Cauchy theorem}

\begin{definition}
    An open set \(\Omega \subset \CC\) is said to be \textbf{simply connected} if every closed contour in \(\Omega\) is homotopic to a point:
    \[\forall \gamma:[0,1] \to \Omega \quad \text{we have} \quad \gamma \sim 0.\]
\end{definition}

\begin{mdthm}[Cauchy's (integral) theorem]
    If \(f\) is holomorphic on an open simply connected set \(\Omega \subset \CC\) we have 
    \[\int_{\gamma} f(z) = 0\]
    for every closed contour, \(\gamma\) in \(\Omega\).
\end{mdthm}

\begin{mdnote}
    This theorem extends the CIF to general contours which are not circles. Thus, simply put if 
    \[\begin{aligned}
        f &\in H(\Omega) \\
        &\text{and} \\
        \gamma &\sim_{\Omega} 0
    \end{aligned}\then \int_{\gamma} f(z) \, dz =0.\]
\end{mdnote}

\begin{mdthm}[G-CIF]
    Let \(f \in H(\Omega)\) and let \(\gamma \sim_{\Omega} 0\). Then 
    \[n(\gamma;a)f(a) = \frac{1}{2\pi i} \int_{\gamma} \frac{f(z)}{z-a} \, dz\]
    for each \(a \in \Omega\) such that \(a \not\in \gamma\).
\end{mdthm}

\begin{mdnote}
    By \(a \not\in \gamma\) we mean that \(a\) does not lie on the path \(\gamma\) but in the area inside the path.
\end{mdnote}

\begin{proof}
    Let
    \[g(z) = \frac{f(z)-f(a)}{z-a}.\]
    By assumption \(f(z) \in H(\Omega)\) so, we know that \(g(z) \in H(\Omega)\). Since the derivative of \(f\) exists at \(a\) we know that 
    \[\lim_{z \to a} g(z) =f'(a).\]
    That is 
    \[g(z) = \begin{cases}
        \frac{f(z)-f(a)}{z-a} & z\neq a \\
        f(z) & z=a,
    \end{cases}\]
    by Cauchy's integral theorem from above we have 
    \[\int_{\gamma} g(z) \, dz =0 \quad \text{i.e.} \quad \int_{\gamma} \frac{f(z)-f(a)}{z-a} \, dz =0.\]
    Thus, 
    \[\begin{aligned}
        0 &= \int_{\gamma} \frac{f(z)-f(a)}{z-a} \, dz \\
        &= \int_{\gamma} \frac{f(z)}{z-a} \, dz -\int_{\gamma} \frac{f(a)}{z-a} \, dz,
    \end{aligned}\]
    that is 
    \[\begin{aligned}
        \int_{\gamma} \frac{f(a)}{z-a} \, dz &=\int_{\gamma} \frac{f(z)}{z-a} \, dz \\
        f(a) \int_{\gamma} \frac{1}{z-a} \, dz &= \int_{\gamma}\frac{f(z)}{z-a} \, dz \\
        f(a)(2\pi i) &=\int_{\gamma}\frac{f(z)}{z-a} \, dz.
    \end{aligned}\]
    We conclude that 
    \[n(\gamma;a)f(a) = \frac{1}{2\pi i} \int_{\gamma} \frac{f(z)}{z-a} \, dz\]
\end{proof}

\subsection{The Cauchy Residue Theorem}

\begin{definition}
    Suppose that \(f: D \backslash \{a\} \to \CC\) be a holomorphic function which has a singularity at \(a\) and let 
    \[f(z) = \sum_{n \in \ZZ} c_n (z-a) \quad \text{for } 0<\abs{z-a}<R.\]
    Then, we call the coefficient \(c_{-1}\) the residue of \(f\) at \(a\), and denote it by 
    \[\text{Res}(f,a).\]
\end{definition}

\begin{mdremark}
    The coefficient \(c_{-1}\) is a special term: if we integrate the power series of \(f(z)\) the term with the coefficient \(c_{-1}\) is the only one that remains. 
\end{mdremark}

\begin{mdthm}[Cauchy Residue Theorem]
    Let \(f\) be a complex function in \(\Omega \subseteq \CC\) with poles at the points \(a_1,a_2, \ldots\) then, for every closed contour \(\gamma\), which is homotopic to a point \(\Omega\) and does not pass through any \(a_k\), we have 
    \[\frac{1}{2\pi i} \int_{\gamma} f(z) \, dz = \sum_{k} n(\gamma,a_k) \, \text{Res}(f,a_k).\]
\end{mdthm}

\begin{mdthm}
    Depending on the form of the function the residue is computed as follows.
    \begin{enumerate}
        \item If
        \[f(z) = \frac{\phi(z)}{z-a} \quad \text{where \(\phi\) is holomorphic at \(a\)}\]
        then 
        \[\text{Res}(f,a)=\phi(a).\]
        \item If
        \[f(z) = \frac{\phi(z)}{(z-a)^m} \quad \text{where \(\phi\) is holomorphic at \(a\)}\]
        then 
        \[\text{Res}(f,a)=\frac{\phi^{(m-1)}(a)}{(m-1)!},\]
        where \(\phi^{(m-1)}(a)\) means the \((m-1)\) derivative of \(\phi\) at \(a\).
        \item If 
        \[f(z) = \frac{\phi(z)}{\psi(z)}\]
        with \(\phi\) and \(\psi\) holomorphic at \(a \in \CC\), and that 
        \[\psi(a)=0 \quad \text{and} \quad \psi'(a)\neq 0,\]
        then \(f\) has a simple pole at \(z=a\) and 
        \[\text{Res}(f,a) = \frac{\phi(a)}{\psi'(a)}.\]
    \end{enumerate}
\end{mdthm}

\begin{mdremark}
    By \(\phi\) being holomorphic at \(a\) we mean that \(\phi\) is differentiable in a (small) disc centred at \(a\).
\end{mdremark}

\subsubsection{Computing contour integrals with the CRT}

\begin{example}
    Using the CRT evaluate the integral 
    \[\int_{\gamma(0,1)} \frac{e^z}{z} \, dz.\]
    \begin{solution}
        Let \(f(z) = \frac{e^z}{z}\), both \(e^z\) and \(z\) are holomorphic everywhere thus, the only pole of \(f(z)\) is at \(z=0\). This implies, 
        \[\text{Res}(f,0)=e^0=1;\]
        since the contour is only traversed once the winding number is \(1\) hence, by the CRT we have 
        \[\int_{\gamma(0,1)} \frac{e^z}{z} \, dz = 2\pi i.\]
    \end{solution}
\end{example}

\begin{example}
    Evaluate the integral
    \[\int_{\gamma} \frac{e^z}{(z-1)(z-3)}\]
    where \(\gamma\) is given by \(\abs{z}=2\) oriented anticlockwise.
    \begin{solution}
        The poles of the integrand are at \(z=1\) and \(z=3\) however, the pole at \(z=3\) lies outside the contour thus, the winding number of this pole is \(0\) which means the associated residue does not contribute the value of the integral. As such, let \(f(z) = \frac{\frac{e^z}{z-3}}{z-1}\) then, \(\text{Res}(f,1)=\phi(1)=\frac{e}{-2}\). By the CRT we have 
        \[\int_{\gamma} \frac{e^z}{(z-1)(z-3)} = -\pi i e.\]
    \end{solution}
\end{example}

\begin{example}
    The integral as above with contour \(\abs{z} =\frac{1}{2}\) will be \(0\) since, the integrand is holomorphic inside the contour.
\end{example}

\begin{example}
    Evaluate the integral 
    \[\int_{\gamma\left(a,\frac{5}{2}\right)} \cot(\pi z) \, dz\]
    traversed anticlockwise once.
    \begin{solution}
        First note that 
        \[\cot(\pi z) = \frac{\cos(\pi z)}{\sin(\pi z)},\]
        and \(\sin(\pi z) =0\) for \(z \in \ZZ\) thus, the poles of \(\cot(\pi z)\) are \(z =n \in \ZZ\). Let \(f(z) = \cot(\pi z)\) then \(\phi(z)=\cos(\pi z)\) and \(\psi(z) = \sin(\pi z)\), as such the residues are given by 
        \[\begin{aligned}
            \text{Res}(f,n) &= \frac{\phi(n)}{\psi'(n)} \\
            &= \frac{\cos(\pi z)}{\pi \cos(\pi z)} \\
            &= \frac{1}{\pi}.
        \end{aligned}\]
        The contour \(\gamma(0,\frac{5}{2})\) contains within it only the integers \(n=-2,-1,0,1,2\) hence, these are the only poles of \(\cot(\pi z)\) which contribute to the integral. Thus, by the CRT we have 
        \[\begin{aligned}
            \int_{\gamma\left(a,\frac{5}{2}\right)} \cot(\pi z) \, dz &= 2\pi i \left(\frac{5}{\pi} \right) \\
            &= 10i.
        \end{aligned}\]
    \end{solution}
\end{example}

\section{Evaluating integrals of the form \texorpdfstring{\(\int_{-\infty}^{\infty} f(x) \, dx\)}{TEXT} via the CRT}

To evaluate an integral of the form \(\int_{-\infty}^{\infty} f(x) \, dx\) over the real line we consider the contour integral \(\int_{C_R} f(z) \, dz\) over a simple closed contour 
\[C_R = [-R,R] \cup A_R\]

where \(f\) is holomorphic on and insider \(C_R\) except  at the poles inside \(C_R\). We can then split the integral as follows 
\[\begin{aligned}
    \int_{C_R} f(z) \, dz &= \int_{[-R,R]} f(z) \, dz + \int_{A_R} f(z) \, dz \\
    &= \int_{-R}^R f(x) \, dx + \int_{A_R} f(z) \, dz/
\end{aligned}\]

As \(R \to \infty\) the aim is to choose \(A_R\) such that 
\[\lim_{R \to \infty} \int_{A_R} f(z) \, dz = 0\]

hence, we can apply the Cauchy Residue Theorem to infer that 

\[\begin{aligned}
    \int_{C_R} f(z) \, dz &= \lim_{R\to\infty} 2\pi i \sum_{k=1}^{m_R} \text{Res}(f,a_k) \\
    &= \int_{-\infty}^{\infty} f(x) \, dx.
\end{aligned}\]

\begin{mdnote}
    Sometimes we may be interested in computing the integral 
    \[\int_{0}^{\infty} f(x) \, dx,\]
    if \(f(x)\) is an even function then 
    \[\int_{-R}^{R} f(x) \, dx = 2\int_{0}^{R} f(x) \, dx.\]
\end{mdnote}


\subsection{Technical toolkit for contour Integration}

\begin{proposition}
    Useful limits:
    \begin{enumerate}
        \item for any constant \(k>0\)
        \[\lim_{x \to \infty} x^k e^{-x} =0 \quad \text{for } x\in \RR;\]
        \item for any constant \(k>0\)
        \[\lim_{x \to \infty} x^{-k} \ln(x)=0 \quad \text{for } x\in \RR,x>0;\]
        \item for any constant \(k>0\)
        \[\lim_{x \to 0} x^k \ln(x) =0 \quad \text{for } x\in \RR,x>0.\]
    \end{enumerate}
\end{proposition}

\begin{proposition}
    Let \(S_N\) be a square with vertices at \((\pm 1 \pm i)(N+\half)\) for \(N \in \NN\) then 
    \begin{itemize}
        \item there exists a constant \(C\) such that \(\abs{\cot(\pi z)}\leq C\) for all \(z \in S_N\);
        \item there exists a constant \(K\) such that \(\abs{\csc(\pi z)}\leq K\) for all \(z \in S_N\);
    \end{itemize}
\end{proposition}

\begin{mdprop}
    Inequalities to remember.
    \begin{enumerate}
        \item Triangle inequality: \(\abs{z_1+z_2} \leq \abs{z_1}+\abs{z_2}\).
        \item Reverse triangle inequality: \(\abs{z_1+z_2} \geq \abs{\abs{z_1}-\abs{z_2}}\).
        \item \(\abs{z_1} \leq \abs{z_2} \iff \frac{1}{\abs{z_1}} \geq \frac{1}{\abs{z_2}}\) for \(z_1,z_2 \neq 0\).
        \item \(\frac{1}{\abs{z_1+z_2}} \leq \frac{1}{\abs{\abs{z_1}-\abs{z_2}}}\).
        \item Repeated triangle inequality: \(\abs{z_1+z_2+ \cdots +z_n} \leq \abs{z_1}+\cdots+ \abs{z_n}\).
        \item Repeated reverse triangle inequality: \(\abs{z_1+z_2+ \cdots +z_n} \geq \abs{z_1}-\abs{z_2}- \cdots - \abs{z_n}\) if \(\abs{z_1} \geq \abs{z_2}+\cdots +\abs{z_n}\).
        \item Estimation theorem:
        \[\abs{\int_{\gamma} f(z) \, dz} \leq \int_{a}^{b} \abs{f(\gamma(t)) \cdot \gamma'(t)} \, dt \leq \sup_{z \in \gamma} \abs{f(z)} \cdot \abs{\gamma'(t)}.\]
        \item If the denominator \(f\) is at least more than two the degree of the numerator it follows that 
        \[\abs{\int_{A_R} f(z) \, dz} \leq \frac{M}{R^2} \cdot \pi R = \frac{M\pi}{R},\]
        where \(A_R\) is the parametrisation of the semicircle.
        \item \textbf{Jordan's inequality}:
        \[\frac{2}{\pi} \leq \frac{\sin\theta}{\theta}\leq 1 \quad \text{for } 0 < \theta \leq \frac{\pi}{2}.\]
        \item Suppose \(\gamma:[a,b] \to C \subset \CC\) is a parametrisation of \(C\). If \(\abs{f(z)}\leq M\) for all \(z \in X\) (i.e. \(f\) is bounded by \(M\) along \(C\)) we have 
        \[\abs{\int_C f(z) \, dz} \leq M L_C,\]
        where \(L_C\) is the length of \(C\).
    \end{enumerate}
\end{mdprop}

\begin{mdremark}
    Joining \((1)\) and \((2)\) together we have 
    \[\abs{\abs{z_1}-\abs{z_2}} \leq \abs{z_1+z_2} \leq \abs{z_1}+\abs{z_2}.\]
    Wolfram alpha says:
    \[\abs{z_1}-\abs{z_2} \leq \abs{z_1+z_2} \leq \abs{z_1}+\abs{z_2}.\]
\end{mdremark}

\begin{example}
    By considering the contour integral 
    \[\int_{C_R} \frac{e^{iz}}{z-ia} \, dz\]
    where \(C_R=[-R,R] \cup A_R\) and \(A_R\) is the semicircle centre at \(0\) and radius \(R>a>0\) in the upper-half plane, show that 
    \[\int_{-\infty}^{\infty} \frac{x\sin x+a\cos x}{x^2+a^2} \, dx = 2\pi e^{-a}\]
    and
    \[\int_{-\infty}^{\infty} \frac{x\cos x-a\sin x}{x^2+a^2} \, dx=0.\]
    \begin{solution}
        Let \(f(z) = \frac{e^{iz}}{z-ia}\); note that it has a pole at \(z=ia\) with residue \(\text{Res}(f,ia)=e^{-a}\). Since, the contour is only traversed once by the CRT we have
        \[\int_{C_R} \frac{e^{iz}}{z-ia} \, dz = 2 \pi i e^{-a}.\]
        Splitting the contour integral over the interval \([-R,R]\), with the parametrisation \(\gamma(x) =x\), and the semicircle \(A_R\) we have 
        \[\int_{-R}^R \frac{e^{ix}}{x-ia} \, dx + \int_{A_R} \frac{e^{iz}}{z-ia} \, dz = 2\pi i e^{-a}.\]
        We now prove 
        \[\lim_{R\to \infty} \int_{A_R} \frac{e^{iz}}{z-ia} \, dz =0.\]
        Consider 
        \[\begin{aligned}
            \abs{\int_{A_R} \frac{e^{iz}}{z-ia} \, dz} &= \abs{\int_{0}^{\pi} \frac{e^{ia(Re^{i\theta})}}{Re^{i\theta}-ia} \cdot Rie^{i\theta} \, d\theta} \\
            &= \abs{\int_{0}^{\pi} \frac{e^{ia[R\cos\theta+iR\sin\theta]}}{Re^{i\theta}-ia} \cdot Rie^{i\theta} \, d\theta} \\
            &\leq \int_{0}^{\pi} \abs{\frac{e^{ia[R\cos\theta+iR\sin\theta]}}{Re^{i\theta}-ia} \cdot Rie^{i\theta}} \, d\theta.
        \end{aligned}\]
        Clearly, 
        \[\begin{aligned}
            \abs{Rie^{i\theta}  \cdot e^{ia[R\cos\theta+iR\sin\theta]}} &= \abs{Rie^{i\theta} \cdot e^{iaR\cos\theta} \cdot e^{-aR\sin\theta}} \\
            &= \abs{Rie^{i\theta}} \cdot \abs{e^{iaR\cos\theta}} \cdot \abs{e^{-aR\sin\theta}} \\
            &= Re^{-aR\sin\theta}.
        \end{aligned}\]
        Furthermore, by the reverse triangle inequality we have
        \[\begin{aligned}
            \abs{Re^{i\theta}+(-ia)} &\geq \abs{\abs{Re^{i\theta}}-\abs{-ia}} \\
            &\geq\abs{R-a},
        \end{aligned}\]
        this implies 
        \[\frac{1}{\abs{Re^{i\theta}-ia}} \leq \frac{1}{\abs{R-a}}.\]
        Therefore,
        \[\abs{\int_{A_R} \frac{e^{iz}}{z-ia} \, dz} \leq \int_{0}^{\pi} \frac{R}{\abs{R-a}} e^{-aR\sin\theta} \, d\theta.\]
        Now, since \(R>a\) we can drop the absolute value, and we note that 
        \[\int_{0}^{\pi} e^{-aR\sin\theta} \, d\theta = 2 \int_{0}^{\frac{\pi}{2}} e^{-aR\sin\theta} \, d\theta.\]
        We conclude that the integral 
        \[\abs{\int_{A_R} \frac{e^{iz}}{z-ia} \, dz} \leq \frac{2R}{R-a} \int_{0}^{\frac{\pi}{2}} e^{-aR\sin\theta} \, d\theta,\]
        by Jordan's inequality we can write 
        \[\frac{2\theta}{\pi} \leq \sin\theta \quad\]
        as such we have 
        \[\begin{aligned}
            \abs{\int_{A_R} \frac{e^{iz}}{z-ia} \, dz} &\leq \frac{2R}{R-a} \int_{0}^{\frac{\pi}{2}} e^{-aR\sin\theta} \, d\theta \\
            &\leq \frac{2R}{R-a} \int_{0}^{\frac{\pi}{2}} e^{-aR \frac{2\theta}{\pi}} \, d\theta \\
            &= \frac{2R}{R-a} \left[ -\frac{\pi}{2aR} e^{-aR \frac{2\theta}{\pi}} \right]_0^{\frac{\pi}{2}} \\
            &= \frac{\pi}{Ra-a^2} (-1) \left( e^{-aR}-1 \right) \\
            &= \frac{\pi}{Ra-a^2}\left( 1-e^{-aR} \right).
        \end{aligned}\]
        Clearly, as \(R\to \infty\) the integral \(\int_{A_R} f(z) \, dz \to 0\) (provided \(a>0\)). Whereas, as \(R\to \infty\) the integral \(\int_{-R}^{R} f(x) \, dx\) becomes 
        \[\begin{aligned}
            \int_{-\infty}^{\infty} \frac{e^{ix}}{x-ia} \, dx = 2\pi i e^{-a}.
        \end{aligned}\]
        To obtain the required integrals we note that 
        \[\begin{aligned}
            \int_{-\infty}^{\infty} \frac{e^{ix}}{x-ia} \, dx &= \int_{-\infty}^{\infty} \frac{(\cos x+i\sin x)(x+ia)}{(x-ia)(x+ia)} \, dx \\
            &= \int_{-\infty}^{\infty} \frac{(x\cos x -a\sin x)+i(a\cos x+x\sin x)}{x^2+a^2} \, dx \\
            &= \int_{-\infty}^{\infty} \frac{x\cos x-a\sin x}{x^2+a^2} \, dx + i \int_{-\infty}^{\infty} \frac{x\sin x+a\cos x}{x^2+a^2} \, dx \\
            &= 0+i(2\pi e^{-a}).
        \end{aligned}\]
        By comparing the real and imaginary part we have:
        \begin{itemize}
            \item real part:
            \[\int_{-\infty}^{\infty} \frac{x\cos x-a\sin x}{x^2+a^2} \, dx = 0;\]
            \item imaginary part:
            \[\int_{-\infty}^{\infty} \frac{x\sin x+a\cos x}{x^2+a^2} \, dx = 2\pi e^{-a}.\]
        \end{itemize}
    \end{solution}
\end{example}

% \begin{mdexample}
%     We present another way to prove \(\int_{A_R} f(z) \, dz \to 0\) as \(R\to \infty\) for the previous problem.
%     \begin{solution}
%         We can write 
%         \[\begin{aligned}
%             \int_{A_R} \frac{e^{iz}}{z-ia} \, dz &=\int_{A_R} \frac{e^{iz}(z+ia)}{(z-ia)(z+ia)} \, dz \\
%             &= \int_{A_R} \frac{e^{iz}(z+ia)}{z^2+a^2} \, dz.
%         \end{aligned}\]
%         By the estimation theorem we have 
%         \[\begin{aligned}
%             \abs{\int_{A_R}\frac{e^{iz}(z+ia)}{z^2+a^2} \, dz} \leq \sup_{z \in C_{A_R}} \abs{\frac{e^{iz}(z+ia)}{z^2+a^2}} \cdot \text{length}(A_R).
%         \end{aligned}\]
%         The contour \(A_R\) is the semicircle in the upper-half of the plane thus, it has length \(\pi R\). 
%         Therefore, 
%         \[\begin{aligned}
%             \abs{\int_{A_R}\frac{e^{iz}(z+ia)}{z^2+a^2} \, dz} &\leq \frac{C}{R^2} \pi R \\
%             &= \frac{C\pi}{R} \\
%             &\to 0 \quad \text{as \(R \to \infty\).}
%         \end{aligned}\]
%         \begin{mdthm}
%             FINISH THIS
%         \end{mdthm}
%     \end{solution}
% \end{mdexample}

\begin{mdexample}
    By considering 
    \[\int_{\gamma_N} \frac{\pi \cot(\pi z)}{z^2} \, dz\]
    where \(\gamma_N\) is the square with vertices at \((\pm 1\pm i)(N+\half)\) oriented anticlockwise and traversed once prove 
    \[\sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}.\]
    \begin{solution}
        The function \(f(z) = \frac{\pi \cot(\pi z)}{z^2}\) is holomorphic except at the poles \(z=0\) and \(z = n \in \ZZ \backslash \{0\}\) (we write it in such way as the residue differs for these poles). We can write 
        \[f(z) = \frac{\frac{\pi \cos(\pi z)}{z^2}}{\sin(\pi z)}\]
        thus, letting \(\phi(z) = \frac{\pi \cos(\pi z)}{z^2}\) and \(\psi(z)=\sin(\pi z)\) the residues 
        \[\begin{aligned}
            \text{Res}(f,n) &= \frac{\frac{\pi \cos(\pi n)}{n^2}}{\pi \cos(\pi n)} \\
            &= \frac{1}{n^2}.
        \end{aligned}\]
        Whereas, (by computing the relevant Laurent expansion of \(f(z)\)) the residue at \(z=0\) is given by 
        \[\text{Res}(f,0)=-\frac{\pi^2}{3}\]
        By the CRT we have 
        \[\int_{\gamma_N} f(z) \, dz = 2\pi i \left( \sum_{n=-N}^{N} \frac{1}{n^2} - \frac{\pi^2}{3} \right).\]
        Note that we can write 
        \[\sum_{n=-N}^{N} \frac{1}{n^2} = 2\sum_{n=1}^{N} \frac{1}{n^2}.\]
        It is now enough to show that \(\int_{\gamma_N} f(z) \, dz \to 0\) as \(N\to \infty\). We have 
        \[\begin{aligned}
            \abs{\int_{\gamma_N} f(z) \, dz} &\leq \sup \abs{\frac{\pi \cot(\pi z)}{z^2}} \cdot \text{length}(\gamma_N) \\
            &\leq \sup \abs{\cot(\pi z)} \frac{4(2N+1)\pi}{\left( N+\half \right)^2} \\
            & \to 0 \quad \text{as \(N \to \infty\)}.
        \end{aligned}\]
        By comparing imaginary part of the integral, we have 
        \[\sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}.\]
    \end{solution}
\end{mdexample}

\section{Existence of primitives}

\begin{mdthm}
    Let \(\Omega \subseteq \CC\) be open. Then 
    \[f\in H(\Omega) \iff f \text{ is complex analytic on } \Omega.\]
\end{mdthm}

\begin{mdnote}
    This theorem is saying that \(f\) is holomorphic on \(\Omega\) if and only if \(f\) has power series expansion on \(\Omega\).
\end{mdnote}

\begin{theorem}
    \[f\in H(\Omega) \then f'\in C(\Omega).\]
\end{theorem}

\begin{mdlemma}
    If \(f \in C(\Omega)\) has a primitive on an open set \(\Omega\) (i.e. there exists \(F \in H(\Omega)\) such that \(F'=f\)) then, \(f \in H(\Omega)\) and \(f'\in C(\Omega)\). Furthermore, \(f^{(k)} \in H(\Omega)\) for all \(k \in \NN\).
\end{mdlemma}

\begin{proof}
    By assumption the primitive \(F\) is a holomorphic function, and it has a continuous derivative \(F'=f\). Therefore, the CIF holds for \(F\) and \(F\) has a power series on every disc \(D \subset \Omega\). Since, we can differentiate power series term by term, the function \(f'(z)\) is also given by a power series on \(D\). This implies that \(f'\) is holomorphic and consequently \(f'\) is continuous. Iterating this, we obtain the final statement.
\end{proof}

\subsection{Morera's and Goursat's theorems}

\begin{mdthm}[Morera's theorem]
    Let \(f\) be a continuous function on an open simply-connected set \(\Omega \subset \CC\). If \\ \(\int_T f(z) \, dz =0\) for any triangular contour \(T\) in \(\Omega\) then, \(f\) has a primitive on \(\Omega\), i.e. \(F \in H(\Omega)\) with \(F'=f\).
\end{mdthm}

\begin{theorem}[Goursat's theorem]
    If \(\Omega\) is simply connected then, 
    \[\int_T f(z) \, dz =0\]
    for any arbitrary triangle \(T\) in \(\Omega\).
\end{theorem}

\begin{mdremark}
    If we only assume \(\int_T f(z) \, dz =0\) for all triangles \(T \subset \Omega\) inside open discs \(D \subset \Omega\), Morera and Goursat's theorems are not necessarily true for \(\Omega\) which are NOT simply connected. 
    \begin{example}
        The function \(z\inv\) is holomorphic on an open annulus \(\Omega\) about the origin and its integrals over all such triangular contours in \(\Omega\) are equal to zero. However, it does not have a primitive on \(\Omega\).
    \end{example}
\end{mdremark}

\begin{mdcor}
    Every holomorphic function \(f\) on an open simply-connected set \(\Omega\) has a primitive.
\end{mdcor}

\begin{corollary}
    For any holomorphic function \(f \in H(\Omega)\) for an open set \(\Omega \subset \CC\) one has \(f^{(k)} \in H(\Omega)\) for all \(k \in \NN\). 
\end{corollary}

\begin{corollary}
    A continuous function \(f\) on a simply connected domain is holomorphic if and only if \(\int_{\gamma} f(z) \, dz=0\) for every closed contour \(\gamma\) in \(\Omega\).
\end{corollary}

\begin{mdthm}
    If \(f\) is continuous on an open set \(\Omega \in \CC\) and \(\int_{\gamma} f(z) \, dz=0\) for every closed contour \(\gamma\) in \(\Omega\) then, \(f\) has a primitive \(F\) on \(\Omega\) and is holomorphic on \(\Omega\).
\end{mdthm}

\section{Singularities of holomorphic function}

\begin{definition}
    Let \(f\) be a complex-valued function which is not defined at a point \(z_0 \in \CC\), and suppose that it is holomorphic in some punctured disc \(D(z_0,R) \backslash \{z_0\}\) so, it is not holomorphic at \(z_0\). Then, we call \(z_0\) an \textbf{isolated singularity} of \(f\).
\end{definition}

\begin{example}
    Each of the functions 
    \[\frac{\sin(z)}{z}, \quad \frac{1}{z^3}, \quad  e^{\frac{1}{z}}\]
    have an isolated singularity at \(0\). 
\end{example}

\begin{definition}
    An isolated singularity \(a\) of \(f\) is called:
    \begin{enumerate}
        \item a \textbf{removable singularity} of \(f\) if the limit \(\lim_{z\to a}\abs{f(z)}\) exists as a finite real number;
        \item a \textbf{pole} of \(f\) if \(\lim_{z\to a} \abs{f(z)}=\infty\);
        \item an \textbf{essential singularity} of \(f\) if \(a\) is neither removable nor a pole.
    \end{enumerate}
\end{definition}

\begin{mdnote}
    We use the name `removable singularity' as we can define a new function \(F\) such that 
    \[F(z) = \begin{cases}
        \lim_{z\to z_0} f(z) &\text{for } z=z_0 \\
        f(z) &\text{otherwise.}
    \end{cases}\]
    Hence, we are effectively removing the singularity.
\end{mdnote}

\begin{mdexample}
    The function \(e^{\frac{1}{z}}\) has an essential singularity at \(0\) as the limit of \(\frac{1}{z}\) as \(z \to 0\) does not exist (because the left and right limits are not equal) thus, by extension the limit of \(e^{\frac{1}{z}}\) as \(z \to 0\) does not exist.
\end{mdexample}

\begin{definition}
    The point \(z=a\) is a zero of a holomorphic function \(f\) if \(f(a)=0\).
\end{definition}

\begin{lemma}
    If \(f \in H(\Omega)\) that is not identically to zero and \(z=a\) is a zero of \(f\) then, \(f\) can be represented in the form 
    \[f(z)=(z-a)^m g(z)\]
    in some neighbourhood of \(z=a\), where \(m \geq 1\) and \(g \in H(\Omega)\).
\end{lemma}

\begin{proof}
    Since \(f \in H(\Omega)\) we can write it as the power series 
    \[\begin{aligned}
        f(z) &= \sum_{n=0}^{\infty} c_n(z-a)^n \\
        &= \sum_{n=m}^{\infty} c_n(z-a)^n \\
        &= (z-a)^m \sum_{n=0}^{\infty} c_{n+m} (z-a)^n \\
        &:=(z-a)^m g(z),
    \end{aligned}\]
    where \(m\) is the smallest index greater than \(0\) such that \(a_m \neq 0\).
\end{proof}

\begin{definition}
    Suppose \(f(a)=0\) and 
    \[f(z)=(z-a)^m g(z)\]
    then, the number \(m\) is called the \textbf{order of the zero} \(z=a\).
\end{definition}

\begin{mdprop}
    The function \(f\) has a zero of order \(m\) at \(z=a\) if and only if 
    \[f(a) = f'(a) =\cdots = f^{(m-1)}(a)=0\]
    but 
    \[f^{(m)}(a) \neq 0.\]
\end{mdprop}

\begin{proposition}
    If \(f \in H(\Omega)\) has distinct zeroes, \(a_1,\ldots,a_n \in \Omega\) of order \(m_1,\ldots, m_n \in \NN\) respectively then,
    \[f(z)= \prod_{k=1}^n (z-a_k)^{m_k} h(z)\]
    where \(h \in H(\Omega)\) and \(h(z) \neq 0\) in each \(D(a_k,R_k)\) for \(R_k>0\).
\end{proposition}

\begin{mdprop}[Compound zeroes]
    If \(f\) and \(g\) have zeroes of order \(m\geq 0\) and \(n \geq 0\), respectively, at \(z=a\) then \(fg\) has a zero of order \(m+n\) at \(a\). 
\end{mdprop}

\begin{definition}
    If \(f\) is defined and holomorphic in a punctured disc \(D(a,R) \backslash \{a\}\), we say that it has a \textbf{pole of order} \(m\) at \(z=a\) if the function \(f(z) = \frac{1}{h(z)}\) (defined to be \(0\) at \(z=a\)) has a zero of order \(m\) at \(z=a\). A pole of order \(1\) is called a \textbf{simple pole}.
\end{definition}

\begin{lemma}
    The function \(f\) has a pole of order \(m\) at \(z=a\) if and only if it can be represented in the form 
    \[f(z) = (z-a)^{-m}g(z)\]
    in a punctured disc centred at \(z=a\), where \(g\) is holomorphic in this disc and \(g(a) \neq 0\).
\end{lemma}

\begin{proposition}
    If \(f\) has poles at \(b_1,\ldots,b_n \in \Omega\) then,
    \[f(z) = \prod_{k=1}^n (z-b)^{-m_k} q(z) \]
    where \(q \neq 0\) and is holomorphic around each pole.
\end{proposition}

\begin{mdthm}[Classification of removable singularity via limits]
    A function \(f \in H(D(a,r) \backslash \{a\})\) has a removable singularity at \(z=a\) if and only if 
    \[\lim_{z\to a} (z-a)f(z)=0.\]
\end{mdthm}

\begin{mdprop}[Riemann’s theorem on removable singularities] Let \(f(z)\) be a holomorphic function which has an isolated singularity at \(a\). Then \(f(z)\) has a removable singularity at \(a\) if and only if \(f(z)\) is bounded for some open disc \(D(a,r)\).
\end{mdprop}

\begin{corollary}
    If \(f\) has a pole at \(z=a\) then, the function \(\frac{1}{f(z)}\) has a removable singularity at \(z=a\).
\end{corollary}

\subsection{Laurent series}

\begin{theorem}[Laurent expansion]
    Let \(0\leq R_1 < R_2 \leq \infty\) and \(A(0,R_1,R_2)\) be the open annulus \(R_1 < \abs{z} < R_2\). If \(f \in H[A(0,R_1,R_2)]\) then, there exist numbers \(c_n \in \CC\) such that 
    \[f(z) = \sum_{n=-\infty}^{\infty} c_n z^n \quad \forall z \in A(0,R_1,R_2).\]
    This series is \underline{\textbf{unique}} and the coefficients
    \[c_m = \frac{1}{2\pi i}\int_{\gamma} \frac{f(z)}{z^{m+1}} \, dz\]
    where \(\gamma\) is an arbitrary anticlockwise oriented circle in \(A(0,R_1,R_2)\). Furthermore, the Laurent series is absolutely and uniformly convergent on the annulus \(A(0,r_1,r_2)\) where \(R_1<r_1<r_2<R_2\).
\end{theorem}

\begin{mdprop}[Classification of singularities via Laurent coefficients]
    If \(f\) has an isolated singularity at \(a\) then, \(f\in H(D(a,r) \backslash \{a\})\) and has a unique Laurent expansion 
    \[f(z) = \sum_{n=-\infty}^{\infty} c_n(z-a)^n.\]
    Then, the point \(z=a\) is said to be
    \begin{itemize}
        \item a \textbf{removable singularity} if \(c_n =0\) for all \(n<0\);
        \item a \textbf{pole of order} \(m \in \NN\) (\(m\geq 1\)) if \(c_{-m} \neq 0\) and \(c_n =0\) for all \(n<-m\);
        \item an \textbf{essential singularity} there are infinitely many negative indices \(n\) such that \(c_n \neq 0\).
    \end{itemize}
\end{mdprop}

\begin{mdnote}
    We can interpret the theorem above as follows: given 
    \[f(z) = \sum_{n=-\infty}^{\infty} c_n(z-a)^n,\]
    if the Laurent series of \(f\):
    \begin{itemize}
        \item has no negative terms then, \(f\) has removable singularity;
        \item has finitely many negative terms we can write 
        \[f(z) = \frac{b_m}{(z-a)^m} + \cdots + \frac{b_1}{z-a} + \sum_{n=0}^{\infty} c_n (z-a)^n\]
        where \(b_m \neq 0\) then, \(f\) has a pole of order \(m\) at \(z=a\);
        \item has infinitely many negative terms then, \(f\) has an essential singularity.
    \end{itemize}
\end{mdnote}

\subsection{Meromorphic functions}

\begin{definition}
    A complex function defined on an open set \(\Omega\) is called \textbf{meromorphic} if it is \textit{holomorphic} in \(\Omega\) except for a set of poles. The set of all meromorphic functions on \(\Omega\) is denoted by \(M(\Omega)\).
\end{definition}

\begin{mdprop}[Identity theorem]
    The following are equivalent for \(f \in H(\Omega)\):
    \begin{enumerate}
        \item \(f \equiv 0\) in \(\Omega\);
        \item there is a point \(a \in \Omega\) and a sequence \(z_n \in \Omega\) with \(z_n\to a\) and \(f(z_n)=0\);
        \item there is a point \(a \in \Omega\) with \(f^{(m)}(a) =0\) for all \(m \in \ZZ_{\geq 0}\).
    \end{enumerate}
\end{mdprop}

\begin{mdremark}
    In literature the Identity theorem is stated as follows.
    \begin{theorem}
        Let \(\Omega \subset \CC\) be a connected open set and let \(f \in H(\Omega)\). The following statements are equivalent:
        \begin{itemize}
            \item \(f \equiv 0\) i.e. \(f(z)=0\) for all \(z \in \Omega\);
            \item the set \(\{z \in \Omega : f(z)=0\}\) has a limit point in \(\Omega\) i.e. there exists a sequence of \underline{distinct} points \(z_k \in \Omega\) such that \(f(z_k)=0\) and \(\lim_{k \to \infty} z_k\) exists and \underline{belongs} to \(\Omega\);
            \item there exists a point \(a \in \Omega\) such that \(f^{(n)}(a)=0\) for every \(n \in \ZZ_{\geq 0}\).
        \end{itemize}
    \end{theorem}
\end{mdremark}

\begin{mdnote}
    Thus, the zeroes (i.e. the roots) of a holomorphic function \(f\), on \(\Omega\) are isolated - meaning there exists \(\delta_a >0\) such that \(z=a\) is the \underline{unique} zero in \(D(a,\delta_a)\) so, there are no other zeroes `nearby'.
\end{mdnote}

\begin{corollary}[Uniqueness theorem]
    Suppose that \(f,g \in \Omega\) and let \((z_n)_{n \in \NN} \subset \Omega\) be a sequence of distinct points which converges to \(a \in \Omega\) and such that for all \(n \in \NN,\) \(f(z_n) = g(z_n)\). Then, \(f(z)=g(z)\) for all \(z \in \Omega\).
\end{corollary}

\begin{mdnote}
    The uniqueness follows by the Identity Theorem: from the fact that two analytic functions that agree on a convergent sequence of point are identical.
\end{mdnote}

\begin{mdexample}
    Let \(f \in H(D(0,2))\). If \(f\left( \frac{1}{n} \right) = \frac{1}{n^2}\) for all \(n \in \NN\) show that \(f(z)=z^2\) for all \(z \in D(0,2)\).
    \begin{solution}
        Let \(g(z)=z^2\) then, 
        \[f \left( \frac{1}{n} \right) = g \left( \frac{1}{n} \right) \quad \forall n \in \NN.\]
        Now, define \(h(z) = f(z)-g(z)\). Clearly, \(z_n = \frac{1}{n} \to 0\) as \(n\to \infty\) thus, there exists a point \(0 \in D(0,2)\) and sequence \(z_n \in D(0,2)\) with \(z_n \to 0\) and \(h(z_n)=0\) which, by the Identity theorem, is equivalent to the statement \(h \equiv 0\) in \(D(0,2)\). Hence,
        \[f(z) = g(z) = z^2.\]
    \end{solution}
\end{mdexample}

\begin{example}
    We provide some examples of applications of the identity theorem. Let \(f\) be analytic on the open disc \(D(0,2)\). 
    \begin{itemize}
        \item If \(f\left( \frac{1}{n} \right) = \frac{1}{n^3}\) for all \(n \in \NN\); define \(h(z) = f(z)- g(z)\) where \(g(z)=z^3\). Clearly, \(f\left( \frac{1}{n} \right) = g\left( \frac{1}{n} \right)\) for all \(n \in \NN\). Since \(z_n = \frac{1}{n} \to 0\) as \(n \to \infty\), we have that \(h(z_n)=0\) therefore, by the Identity theorem, we have the equivalent statement 
        \[f(z)=g(z)=z^3.\]
        \item If \(f\left( \frac{1}{n} \right)=f\left( -\frac{1}{n} \right)=\frac{1}{n^2}\) for all \(n \in \NN\) then \(f(z)=z^3\) for all \(z \in D(0,2)\).
        \item If \(f\left( \frac{1}{n} \right)= f\left( -\frac{1}{n} \right)=\frac{1}{n^3}\) for all \(n \in \NN\). Consider \(f\left( \frac{1}{n} \right) = \frac{1}{n^3}\) then, \(f(z)=z^3\) for all \(z \in D(0,2)\). However, considering \(f\left( -\frac{1}{n} \right) = \frac{1}{n^3}\) then, \(f(z)=-z^3\) for all \(z \in D(0,2)\). Hence, no such \(f \in H(D(0,2))\) exists.
    \end{itemize}
\end{example}

\begin{proposition}
    The function \(f \in M(\Omega)\) has a pole of order \(m>0\) at \(z=a\) if and only if \(\frac{1}{f} \in H(\Omega)\) has a zero of order \(m\) at \(z=a\).
\end{proposition}

\begin{mdprop}
    Let \(\Omega \subset \CC\) be bounded then, \(f \in M(\Omega)\) has only finitely many zeroes and poles in \(\Omega\). Let \(a_1,\ldots, a_p \in \Omega\) denote the zeroes of \(f\) with respective multiplicities \(m_1,\ldots,m_p \in \NN\). Let \(b_1, \ldots,b_q \in \Omega\) denote the poles of \(f\) with respective multiplicities \(r_1, \ldots, r_q \in \NN\). Then, \(f\) can be written 
    \[f(z) = \frac{\prod_{i=1}^{p}(z-a_i)^{m_i}}{\prod_{j=1}^{q}(z-b_j)^{r_j}}h(z)\]
    where \(h \in H(\Omega)\) has no zeroes in \(\Omega\).
\end{mdprop}

\subsubsection{Counting zeroes of meromorphic functions}

\begin{definition}
    Let \(\gamma \sim 0\) and let \(f \in M(\Omega)\) with poles \(b_1,b_2,\ldots,b_n\) of multiplicities \(r_1,r_2,\ldots,r_n\). Then the \textbf{number of poles} of the function \(f\) counted with multiplicity is defined to be 
    \[P_{\gamma}(f) = \sum_{k=1}^n r_k n(\gamma,b_k) \in \ZZ.\]
\end{definition}

\begin{mdremark}
    Above we have assumed that \(b_i \not\in \gamma\).
\end{mdremark}

\begin{definition}
    We define the \textbf{index} of \(f \in M(\Omega)\) relative to such a closed contour \(\gamma\) by 
    \[\text{Ind}_{\gamma}(f)=Z_{\gamma}(f)-P_{\gamma}(f).\]
\end{definition}

\begin{mdremark}
    Recall that the winding number is also called the index, we can think of this version of the index as one defined for \ul{meromorphic} functions.
\end{mdremark}

\begin{mdthm}
    For \(f \in H(\Omega)\) one has 
    \[\text{Ind}_{\gamma}(f)=w_{\gamma}(f).\]
\end{mdthm}

\begin{mdexample}
    Given the function 
    \[f(z)= \frac{(z-4)(z-1)^2\sin z}{z^2+1}\]
    evaluate the integral 
    \[\int_C \frac{f'(z)}{f(z)} \, dz\]
    where \(C\) is the positively oriented contour with \(\abs{z}=2\).
    \begin{solution}
        Recall that the index of a function over a closed contour is equal to its winding number over the same contour. Recall the winding number is given by 
        \[w_{\gamma}(f) = \frac{1}{2\pi i} \int_{\gamma} \frac{f'(z)}{f(z)} \, dz,\]
        and the index of a function is 
        \[\text{Ind}_{\gamma}(f)=Z_{\gamma}(f)-P_{\gamma}(f).\]
        Therefore, 
        \[\int_{C} \frac{f'(z)}{f(z)} \, dz = 2\pi i\left( Z_{C}(f)-P_{C}(f) \right).\]
        The function \(f(z)\) has zeros at \(4, 1\) (double zero), and \(k\pi\) with \(k \in \ZZ\). The only zeros inside \(C\) are \(1\) (double) and \(0\). Therefore, \(Z_C(f) = 3\). The poles are at \(\pm i\) and they both lie inside \(C\). Therefore,
        \[\begin{aligned}
            \int_{C} \frac{f'(z)}{f(z)} \, dz &= 2\pi i\left( 3-2\right) \\
            &= 2\pi i.
        \end{aligned}\]
    \end{solution}
\end{mdexample}

\begin{corollary}
    Let \(f,g\in M(\Omega)\) such that \(f,g\) and \(f \cdot g\) have no zeroes or poles in \(\gamma\) then,
    \[\text{Ind}_{\gamma}(f \cdot g)=\text{Ind}_{\gamma}(f)+\text{Ind}_{\gamma}(g).\]
\end{corollary}

\begin{corollary}
    One has 
    \[\text{Ind}_{\gamma}\left( \frac{1}{f} \right) = - \text{Ind}_{\gamma}(f).\]
\end{corollary}

\begin{mdthm}
    If \(\gamma_1 \sim \gamma_2\) and the homotopy does not pass through any zero or pole of \(f \in M(\Omega)\) then,
    \[\text{Ind}_{\gamma_1}(f)=\text{Ind}_{\gamma_2}(f).\]
\end{mdthm}

\begin{theorem}
    If \(f_1,f_2 \in M(\Omega)\) are homotopic via a homotopy \(F : [0,1] \times \Omega \to \CC\) with \(z \mapsto F(t,z) \in M(\Omega)\) and satisfies
    \[F(0,z)=f_1(z) \quad \text{and} \quad F(1,z)=f_2(z)\]
    such that no zero or pole of \(F(t,z)\) lies in \(\gamma\) for any \(t\) then,
    \[\text{Ind}_{\gamma}(f_1)=\text{Ind}_{\gamma}(f_2).\]
\end{theorem}

\subsection{Counting zeroes of holomorphic functions}

\begin{definition}
    Let \(\gamma \sim 0\) and let \(f \in H(\Omega)\) with zeroes \(a_1,a_2,\ldots,a_n\) of multiplicities \(m_1,m_2,\ldots,m_n\). Then the \textbf{number of zeroes} of the function \(f\) counted with multiplicity is defined to be 
    \[Z_{\gamma}(f) = \sum_{k=1}^n m_k n(\gamma,a_k) \in \ZZ.\]
\end{definition}

\begin{mdthm}[Zero counting theorem]
    Let \(\gamma \sim_{\Omega} 0\) and let \(f \in H(\Omega)\) with zeroes \(a_1,a_2, \ldots,a_n\) of multiplicities \\ \(m_1,m_2,\ldots,m_n\). Then,
    \[Z_{\gamma}(f) = w_{\gamma}(f).\]
\end{mdthm}

\begin{corollary}
    Let \(f,g \in H(\Omega)\) then 
    \[Z_{\gamma}(f\cdot g) =Z_{\gamma}(f) + Z_{\gamma}(g).\]
\end{corollary}

\begin{mdthm}[Rouché's theorem]
    Let \(\Omega\) be a simply connected set and let \(\gamma\) be a simple closed contour in \(\Omega\). If \(f,g \in H(\Omega)\) and \(\abs{g(z)}<\abs{f(z)}\) for all \(z \in \gamma\) then, \(f\) and \(f+g\) have the same number of zeroes inside \(\gamma\).
\end{mdthm}

\begin{mdexample}
    Determine the number of zeroes for \(h(z)=z^7-2z^3+7\) inside the disc \(\abs{z}\leq 2\).
    \begin{solution}
        Let \(h(z)=f(z)+g(z)\), we choose \(f(z)\) such that \(\abs{g(z)}<\abs{f(z)}\) so, we write a table to determine the dominant terms of \(h(z)\).
            \begin{table}[H]
                \centering
                \begin{tabular}{c|c}
                Term & \(\abs{\text{term}}\) when \(\abs{z}=2\) \\ \hline
                \(z^7\)   & \(2^7=128\)     \\ 
                \(-2z^3\) & \(2^4=16\)     \\ 
                \(7\)    & \(7\)     \\ 
                \end{tabular}
                \end{table}
        \noindent Therefore, we choose \(f(z)=z^7\) and \(g(z)=7-2z^3\). Clearly, \(\abs{g(z)}<\abs{f(z)}\) and both functions are holomorphic inside and on the disc. By Rouché's theorem, \(f(z)=z^7\) and \(f(z)+g(z)=h(z)\) have the same number of zeroes on the disc \(\abs{z}\leq 2\). In conclusion, since \(f(z)\) has \(7\) zeroes on the disc then so does \(h(z)\). 
    \end{solution}
\end{mdexample}

\subsection{Essential singularities}

\begin{mdthm}[Casorati-Weierstrass]
    If \(f \in H[D(a,r) \backslash \{a\}]\) and has an essential singularity at \(z=a\) then, the image \(f(D(a,R) \backslash \{a\})\) of the punctured disc is dense in \(\CC\).
\end{mdthm}

\section{Liouville's theorem}

\begin{mdthm}[Liouville's theorem]
    Let \(f \in H(\CC)\) and let \(f\) be a bounded function. Then, \(f\) is constant.
\end{mdthm}

\begin{proof}
    Since \(f\) is entire we can write 
    \[f(z) = \sum_{n=0}^{\infty} c_n z^n\]
    where 
    \[c_n = \frac{f^{(n)}(0)}{n!} =\frac{1}{2\pi i} \int_{\gamma(0,R)} \frac{f(w)}{w^{n+1}} \, dw,\]
    where \(\gamma(0,R)\) is a circle of radius \(R>0\) of centre \(0\). Suppose \(f\) is bounded by \(M\) i.e. \(\abs{f(z)} \leq M\) for all \(z \in \CC\). We can estimate 
    \[\begin{aligned}
        \abs{c_n} &= \abs{\frac{1}{2\pi i} \int_{\gamma(0,R)} \frac{f(w)}{w^{n+1}} \, dw} \\
        &\leq \frac{1}{2\pi} \cdot \text{Length}(\gamma(0,R)) \cdot \max_{z \in \gamma(0,R)} \abs{\frac{f(w)}{w^{n+1}}} \\
        &= \frac{1}{2\pi} \cdot 2\pi R \cdot \frac{M}{R^{n+1}} \\
        &= \frac{M}{R^n}.
    \end{aligned}\]
    Where we have used the fact \(\abs{z}=R\) on the circle \(\gamma(0,R)\). Since, the choice of \(R\) was an arbitrary positive number by letting \(R\) tend to infinity (we let \(R\) tend to infinity since \(f\) is analytic on the entire plane) gives \(c_n = 0\) for all \(n \geq 1\). Thus, \(f(z) = c_0\) i.e. \(f\) the constant function.
\end{proof}

\begin{mdcor}
    If there exists \(M >0\) such that 
    \[\abs{f(z)} < M\abs{z}^m \quad \text{for } m\in \ZZ_{\geq 0} \text{ and } \forall z \in \CC\]
    then, \(f(z)\) is a polynomial of order at most \(m\).
\end{mdcor}

\begin{theorem}[Fundamental theorem of algebra]
    Let \(p(z)\) be a non-constant polynomial with complex coefficients. Then, there exists \(\zeta \in \CC\) such that \(p(\zeta)=0\). Consequently, a complex polynomial of degree \(n>1\) has \(n\) roots (not necessarily distinct) in \(\CC\).
\end{theorem}

\begin{proof}
    For the sake of contradiction, suppose that \(p(z) \neq 0\) for all \(z\). Since \(\abs{p(z)} \to \infty\) as \(\abs{z} \to \infty\), there exists \(R\) such that \(\abs{\frac{1}{p(z)}}<1\) for \(\abs{z}>R\). On the closed disc \(\overline{D}(0,R)\) \(\frac{1}{p(z)}\) is continuous which implies it is bounded. Hence, \(\frac{1}{p(z)}\) is bounded on \(\CC\). It is also holomorphic on \(\CC\) so, by Liouville's theorem \(\frac{1}{p(z)}\) is constant, which is a contradiction.
\end{proof}

\begin{mdcor}
    If \(P \in H(\CC)\) such that
    \[\abs{P(z)}\leq C \left( \abs{z}+1 \right)^n\]
    for some \(C >0\) and \(n \in \NN\) then, \(P(z)\) is a polynomial.
\end{mdcor}

% \begin{proof}
%     We present a proof by induction. Assume that the results holds for all \(n'<n\), and consider an entire function \(P\) satisfying the above estimate. Let \(P(0)=a\). Then, \(P(z)-a\) is also an entire function which satisfies the estimate 
%     \[\abs{P(z)-a}\leq (C+\abs{a})(\abs{z}+1)^n.\]
%     The point \(z=0\) is a root of the function \(P(z)-a\) therefore, 
%     \[P(z)-a = z^m P_0(z)\]
%     where \(m\) is the multiplicity of the root and \(P_a\) is another entire function. 
% \begin{mdthm}
%     TO FINISH
% \end{mdthm}
% \end{proof}

\begin{corollary}
    A polynomial \(P(z)\) of degree \(n\) can be written as the product
    \[P(z) =c(z-a_1)^{m_1}(z-a_2)^{m_2} \cdots (z-a_k)^{m_k},\]
    where \(a_j\) are the roots of \(P\) of multiplicity \(m_j\) and \(c\) is a constant.
\end{corollary}

\section{The maximum modulus theorem}

\begin{mdthm}[Maximum Modulus Theorem]
    Let \(\Omega \subset \CC\) be an open and connected set and let  \(f \in H(\Omega)\) with \(f' \in C(\Omega)\). If \(\abs{f}\) obtains its maximum at some point \(z_0 \in \Omega\) then, \(f\) is constant.
\end{mdthm}

\begin{mdexample}
    Does there exist a holomorphic function on the disc \(D(0,1)\) with 
    \[\abs{f \left( \frac{z}{2} \right)} > \abs{f(z)}?\]
    \begin{solution}
        The condition above implies that \(\abs{f}\) attains its maximum at \(z=0\). By the MMT then, \(f(z)\) is constant which contradicts the above assumption. Therefore, no such \(f\) exists.
    \end{solution}
\end{mdexample}

\begin{mdthm}[MMT 2]
    Let \(\Omega \subset \CC\) be an open and connected set and let  \(f \in H(\Omega)\) with \(f' \in C(\Omega)\). If \(\abs{f}\) obtains its maximum at some point \(z_0 \in \Omega\) then, \(\abs{f}\) attains its maximum on the boundary \(\partial \overline{\Omega} = \overline{\Omega} \backslash \Omega\).
\end{mdthm}

\begin{mdremark}
    The notation \(\overline{\Omega}\) indicates the closure of \(\Omega\).
\end{mdremark}

\begin{mdexample}
    Let \(\Omega = D(0,1)\) then, \(\overline{\Omega} = \overline{D}(0,1) = \{z \in \CC : \abs{z} \leq 1\}\) and \(\partial \overline{\Omega} = \abs{z}\). Consider the function \(f(z)=e^z\), this is clearly holomorphic on \(\Omega\) and \(\partial \Omega\). With \(z=x+iy\) we have 
    \[\abs{f(z)}=\abs{e^z}=e^x\]
    so, its maximum is the maximum of the real valued function \(e^x\) which occurs at \(x=1\).
\end{mdexample}

\pagebreak

\appendix

\addcontentsline{toc}{section}{Appendix}
\section*{Appendix}

\section{Roots of unity}

Suppose we want to solve the equation 
\[z^n =1 \quad \text{for } n \in \NN,\]
since \(1 \in \CC\) we can write it in exponential polar form:
\[\begin{aligned}
    1 &= e^{2\pi i k} \quad \text{for } k \in \ZZ \\
    &= \cos(2\pi k) +i \sin(2\pi k).
\end{aligned}\]

Therefore, we have 

\[\begin{aligned}
    z^n &= 1 \\
    z &= 1^{\frac{1}{n}} \\
    &= \left( \cos(2\pi k) +i \sin(2\pi k) \right)^{\frac{1}{n}} \\
    &= \cos \left(\frac{2\pi k}{n}\right) +i \sin\left(\frac{2\pi k}{n}\right)
\end{aligned}\]

We conclude with the following observation:
\begin{itemize}
    \item the roots of unity lie on the unit circle;
    \item they are equally separated by an angle of \(\frac{2\pi}{n}\).
\end{itemize}

\begin{definition}
    Let \(\zeta \in \CC\) and \(n\) a positive integer. The number \(\zeta\) is called an \(n\)-th \textbf{root of unity} if \(\zeta^n=1\).
\end{definition}

\begin{mdthm}
    Let \(n\) be a positive integer. Define 
    \[\begin{aligned}
        \omega_n &= \cos \left( \frac{2\pi}{n} \right) + i\sin \left( \frac{2\pi}{n} \right) \\
        &= e^{i \frac{2\pi}{n}}.
    \end{aligned}\]
    We have:
    \begin{itemize}
        \item \(\omega_n\) is an \(n\)-th root of unity;
        \item the \(n\)-th roots of unity are the \(n\) complex numbers of modulus \(1\), given by \(1,\omega_n,\omega_n^2,\ldots, \omega_n^{n-1}\).
    \end{itemize}
\end{mdthm}

\begin{corollary}
    Let \(n\) be a positive integer and \(\omega_n\) an \(n\)-th root of unity. Then, the polynomial 
    \[z^n-1=(z-1)(z-\omega_n)(z-\omega_n^2)\cdots(z-\omega_n^{n-1}).\]
\end{corollary}

\end{document}